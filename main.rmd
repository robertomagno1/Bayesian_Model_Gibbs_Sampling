---
title: Homework \#02
author: SMDS-2024-2025
date:  |
  | \textsc{\textbf{\Large Statstical Methods in Data Science II a.y. 2024-2025}}
  | 
  | M.Sc. in Data Science
  | 
  | \underline{deadline: 12 June, 2025}
output:
  pdf_document:
    keep_tex: yes
    toc: no
  html_document:
    keep_md: yes
    theme: united
header-includes: 
- \usepackage{transparent}
- \usepackage[utf8]{inputenx}
- \usepackage{iwona}
- \usepackage{tikz}
- \usepackage{dcolumn}
- \usepackage{color}
- \usepackage[italian]{babel}
- \usepackage{listings}
- \usepackage{hyperref}
- \usepackage{setspace}
- \usepackage{enumitem}
- \usepackage{tocloft}
- \usepackage{eso-pic}
- \geometry{verbose,tmargin=5cm,bmargin=3.5cm,lmargin=2.5cm,rmargin=2.5cm}
<font color="#FF0000"></font>

\bigskip
---

```{r setup, include=FALSE}
library(knitr)

knitr::opts_chunk$set(echo = TRUE)

# the default output hook
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x = unlist(stringr::str_split(x, '\n'))
    if (length(x) > n) {
      # truncate the output
      x = c(head(x, n), '....\n')
    }
    x = paste(x, collapse = '\n') # paste first n lines together
  }
  hook_output(x, options)
})
```

```{r, include=FALSE, warning=FALSE}

options(width=60)
opts_chunk$set(out.lines = 23, comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = TRUE, size="small",tidy.opts=list(width.cutoff=50), fig.align = 'center', fig.width = 5, fig.height = 4)
```

```{r,echo=FALSE}
set.seed(123)
```

## 1. A/R algorithm

1)  Suppose one wants to draw a random sample of size $n=10000$ (with i.i.d. components) from a distribution whose density is **proportional** to the following target finite measure density $f(x)=\text{exp}\{-0.5 x^2\}$ by means of the Acceptance Rejection (A/R) algorithm with a suitable number $N$ of draws from a standard Cauchy distribution;

<!-- -->

a)  provide the normalizing constant of the target density $f(x)$ and the expression of the normalized probability density $\tilde{f}(x)$;

## 1a. Normalizing constant and normalized density

We are given the unnormalized density function:

$$
f(x) = \exp\left(-\frac{1}{2}x^2\right)
$$

This is a well-known functional form, which corresponds to the unnormalized version of the standard normal distribution density.

## I first recognizing the form of the normal gaussian distrution N(0,1) so

recall the standard normal distribution:

$$
\tilde{f}(x) = \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}x^2\right)
$$

By comparing the two expressions, we see that:

$$
f(x) = \sqrt{2\pi} \cdot \tilde{f}(x)
$$

Thus, the normalizing constant is:

$$
Z = \int_{-\infty}^{+\infty} \exp\left(-\frac{1}{2}x^2\right) dx = \sqrt{2\pi}
$$

Normalized density expression:  by dividing the unnormalized density by the constant $Z$, we obtain the normalized density:

$$
\tilde{f}(x) = \frac{1}{Z} f(x) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{1}{2}x^2\right)
$$

This is the standard normal density \$ \mathcal{N}(0,1)\$

b)  provide a geometric interpretation of the normalizing constant of the target density $f(x)$ in terms of its graphical representation;

# 2  Markov chain (three‑state “frog” example)

```{r transition}
P <- matrix(c(
  0,   0.5, 0.5,
  5/8, 1/4, 1/8,
  1/3, 2/3, 0),
  nrow = 3, byrow = TRUE)
rownames(P) <- colnames(P) <- 1:3
P
```

## 2a  Simulate one chain (1000 steps) starting at state 1

```{r single-chain}
sim_chain <- function(n, start, P){
  s <- integer(n); s[1] <- start
  for(t in 2:n){
    s[t] <- sample(1:3, 1, prob = P[s[t-1], ])
  }
  s
}

chain1 <- sim_chain(1000, 1, P)
prop.table(table(chain1))
```

## 2b  Empirical relative frequencies

Already displayed above.

## 2c  500 chains – record only the final state

```{r many-chains}
set.seed(321)
end_states <- replicate(500, tail(sim_chain(1000, 1, P), 1))
prop_end <- prop.table(table(end_states))
prop_end
```

## 2d  Theoretical stationary distribution

```{r stationary}
library(expm)  # for eigen‑decomposition if not base
pi_stat <- eigen(t(P))$vectors[,1]
pi_stat <- Re(pi_stat / sum(pi_stat))
pi_stat
```

## 2e  Comparison

```{r compare}
comparison <- rbind(
  "Single‑chain empirical" = prop.table(table(chain1)),
  "500‑chains final state" = prop_end,
  "Stationary π"          = pi_stat
)
round(comparison, 3)
```

## 2f  Starting from state 2

```{r start2}
end_states2 <- replicate(500, tail(sim_chain(1000, 2, P), 1))
prop.table(table(end_states2))
```

We still converge to π, illustrating that the chain is ergodic: the initial state does not affect long‑run behaviour.

---

```{r last-update, echo=FALSE}
cat(paste0("Last knit: ", Sys.time()))

```

c)  provide a suitable constant $k$ which allows you to implement the Acceptance-Rejection algorithm to draw a sample from the normalized probability density $\tilde{f}(x)$ by means of i.i.d. draws from the Cauchy distribution;



## Part (c): Finding a Suitable Constant $k$

We are given:

- **Target density** (up to a constant):  
$$
f(x) = e^{-0.5x^2}
$$
  which is proportional to a standard normal density.

- **Proposal distribution**: standard Cauchy, with density  

$$
g(x) = \frac{1}{\pi (1 + x^2)}
$$

We aim to find a suitable constant $$k$$ such that:  
$$
\tilde{f}(x) \leq k \cdot g(x), \quad \forall x \in \mathbb{R}
$$

To find $$k$$, we consider the supremum of the ratio:
$$
k = \sup_{x \in \mathbb{R}} \frac{\tilde{f}(x)}{g(x)}
$$

Since $$\tilde{f}(x)$$ is the standard normal density:
$$
\tilde{f}(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}
$$

So:
$$
\frac{\tilde{f}(x)}{g(x)} = \frac{\frac{1}{\sqrt{2\pi}} e^{-x^2/2}}{\frac{1}{\pi (1 + x^2)}} = \frac{\pi}{\sqrt{2\pi}} \cdot \frac{e^{-x^2/2}}{1 + x^2}
$$

Now compute this in R and find the maximum:

```{r find-k}
target_over_cauchy <- function(x) {
  (pi / sqrt(2 * pi)) * exp(-0.5 * x^2) / (1 + x^2)
}

# Optimize the function over a symmetric large interval (e.g., -100 to 100)
opt_result <- optimize(function(x) -target_over_cauchy(x), interval = c(-100, 100))

k <- -opt_result$objective
k
```

This value of $$k$$ ensures that for all $$x$$, $$\tilde{f}(x) \leq k \cdot g(x)$$, making it suitable for use in the A/R algorithm.


d)  provide your R code for the implementation of the A-R;

Implementation of the Acceptance-Rejection Algorithm

We now implement the A-R algorithm using the computed value of $$k$$ to sample from the normalized density $$\tilde{f}(x)$$ using i.i.d. samples from the standard Cauchy proposal.

```{r ar-implementation}
set.seed(123)
n <- 10000  # desired number of accepted samples
samples <- numeric(n)
rejected <- numeric()
i <- 0
trials <- 0

while (i < n) {
  x_candidate <- rcauchy(1)
  u <- runif(1)

  f_x <- dnorm(x_candidate)  # standard normal density
  g_x <- dcauchy(x_candidate)  # standard Cauchy density

  if (u <= f_x / (k * g_x)) {
    i <- i + 1
    samples[i] <- x_candidate
  } else {
    rejected <- c(rejected, x_candidate)
  }
  trials <- trials + 1
}

# Report the acceptance rate
acceptance_rate <- n / trials
acceptance_rate
```

## Part (e): Monte Carlo Estimate of Acceptance Probability

```{r acceptance-probability}
cat("Acceptance rate (MC estimate):", acceptance_rate, "\n")
```



This code returns 10,000 accepted samples from the target density $$\tilde{f}(x)$$ and computes the empirical acceptance rate of the algorithm.


e)  evaluate numerically (approximately by MC) the acceptance probability;
// as written up , 

f)  write your theoretical explanation about how you have conceived your Monte Carlo estimate of the acceptance probability;
## Part (e): Monte Carlo Estimate of Acceptance Probability

We can now report the acceptance probability from the previous simulation, which was computed as the number of accepted samples over total proposals:

```{r acceptance-probability}
cat("Acceptance rate (MC estimate):", acceptance_rate, "\n")
```

This Monte Carlo estimate provides a numerical approximation of the theoretical acceptance probability:
$$
P(\text{accept}) \approx \frac{1}{k} \int \frac{\tilde{f}(x)}{g(x)} g(x) dx = \frac{1}{k} \int \tilde{f}(x) dx = \frac{1}{k}
$$

Empirically:
- If $$k \approx 2.5$$, the theoretical acceptance rate is $$1/k \approx 0.4$$.
- The MC simulation gives an estimate close to this value, validating the approach.


g)  save the rejected simulations and provide a graphical representation of the empirical distribution (histogram or density estimation);


Saving and Visualizing Rejected Simulations

We now visualize the empirical distribution of the rejected samples.

```{r rejected-plot, warning=FALSE, message=FALSE}
library(ggplot2)

# Create a data frame
rejected_df <- data.frame(x = rejected)

# Plot histogram and density estimation
ggplot(rejected_df, aes(x = x)) +
  geom_histogram(aes(y = ..density..), bins = 100, fill = "lightblue", alpha = 0.6) +
  geom_density(color = "darkblue", size = 1.2) +
  xlim(-10, 10) +
  labs(title = "Empirical Distribution of Rejected Samples",
       x = "x (Rejected Samples)",
       y = "Density") +
  theme_minimal()
```

This plot gives a visual understanding of where most of the rejections occur relative to the Cauchy proposal and the standard normal target.

h)  derive the theoretical density corresponding to each rejected random variable and try to compare it to the empirical distribution;

i)  explain why one cannot fix in advance an (almost sure) fixed number $N$ of simulations from the auxiliary distribution necessary to get the desired number of $n=10000$ random draws form $\tilde{f}(x)$.
