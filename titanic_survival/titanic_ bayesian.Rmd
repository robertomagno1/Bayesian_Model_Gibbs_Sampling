---
title: "Analisi Bayesiana della Sopravvivenza dei Passeggeri del Titanic: Studio Gerarchico Completo"
author: "Roberto Giuggini - Analisi Bayesiana Avanzata"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    keep_tex: true
    latex_engine: xelatex
    number_sections: true
  html_document:
    theme: flatly
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    code_folding: show
mainfont: Times New Roman
sansfont: Times New Roman
always_allow_html: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
# ============================================================================
# GLOBAL SETUP AND LIBRARY LOADING
# ============================================================================

# Impostazioni globali per i chunk di codice knitr
knitr::opts_chunk$set(
  echo       = TRUE,
  warning    = FALSE,
  message    = FALSE,
  cache      = FALSE,  # FIXED: Disabled cache for JAGS models
  cache.lazy = FALSE,
  fig.align  = "center",
  fig.width  = 8,
  fig.height = 6,
  dpi        = 300,
  comment    = "",
  out.width  = "100%"
)

# Caricamento delle librerie necessarie per l'analisi
suppressPackageStartupMessages({
  library(readr)
  library(dplyr)
  library(ggplot2)
  library(rjags)
  library(coda)
  library(ggmcmc)
  library(forcats)
  library(knitr)
  library(kableExtra)
  library(bayesplot)
  library(corrplot)
  library(gridExtra)
  library(scales)
  library(tidyr)
  library(lme4)
  library(stringr)  # FIXED: Added missing stringr package
})

# Impostazione tema globale per i grafici
theme_set(theme_minimal() + 
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.position = "bottom",
    legend.title = element_text(size = 11, face = "bold"),
    strip.text = element_text(size = 11, face = "bold"),
    panel.grid.minor = element_blank()
  ))

# Configurazione colori personalizzati
custom_colors <- c("#2E86AB", "#A23B72", "#F18F01", "#C73E1D")
```

# Introduzione e Motivazione: Un Viaggio nella Storia attraverso la Statistica Bayesiana

## Il Fascino Storico del Titanic e l'Opportunit√† Scientifica

Il naufragio del RMS Titanic nella notte del 14-15 aprile 1912
rappresenta una delle tragedie marittime pi√π documentate della storia
moderna. **Ma oltre alla sua importanza storica, questo evento ci offre
un'opportunit√† scientifica straordinaria**: un dataset ricco e complesso
che ci permette di esplorare i fattori che hanno determinato la
sopravvivenza umana in condizioni estreme.

**Perch√© l'Approccio Bayesiano √® Rivoluzionario per questa Analisi?**

L'analisi Bayesiana non √® semplicemente un'alternativa alle metodologie
frequentiste - √® una **filosofia completamente diversa** di fare
inferenza statistica che si allinea perfettamente con la natura
dell'investigazione storica:

1.  **Quantificazione Naturale dell'Incertezza**: A differenza degli
    approcci frequentisti che forniscono stime puntuali, l'approccio
    Bayesiano ci d√† **distribuzioni complete di probabilit√†** per ogni
    parametro, permettendoci di affermare con precisione quanto siamo
    certi delle nostre conclusioni.

2.  **Incorporazione della Conoscenza Storica**: Le distribuzioni a
    priori ci permettono di incorporare la conoscenza storica
    pre-esistente sul comportamento umano in situazioni di emergenza,
    rendendo l'analisi pi√π ricca e realistica.

3.  **Modellazione Gerarchica Naturale**: La struttura gerarchica dei
    dati del Titanic (passeggeri raggruppati per porto d'imbarco,
    classe, ecc.) trova nella metodologia Bayesiana la sua
    rappresentazione pi√π naturale e potente.

## Obiettivi Scientifici Ambiziosi

**Questa analisi va oltre la semplice identificazione dei fattori di
sopravvivenza**. I nostri obiettivi sono:

-   **Quantificare con precisione probabilistica** l'impatto di ogni
    fattore sulla sopravvivenza
-   **Sviluppare un modello predittivo robusto** che possa generalizzare
    a situazioni simili
-   **Dimostrare la superiorit√† metodologica** dell'approccio Bayesiano
    attraverso confronti rigorosi
-   **Validare l'affidabilit√†** delle nostre inferenze attraverso
    tecniche avanzate di model checking

# Illustrazione del Dataset: Esplorando i Dati che Raccontano una Storia

```{r data-loading-exploration}
# ============================================================================
# CARICAMENTO E ESPLORAZIONE DATI: IL PRIMO SGUARDO ALLA STORIA
# ============================================================================

# Caricamento dati grezzi - ogni riga rappresenta una vita umana, una storia
titanic_raw <- read_csv('/Users/roberto/Desktop/titanic_project/train (2).csv', 
                        show_col_types = FALSE)

# Panoramica iniziale del dataset - dimensioni che raccontano la tragedia
cat("üö¢ DATASET TITANIC: UNA FINESTRA SULLA STORIA\n")
cat("üìä Dimensioni del dataset:", nrow(titanic_raw), "vite documentate,", ncol(titanic_raw), "caratteristiche registrate\n\n")

# Ogni variabile racconta un aspetto della tragedia
cat("üìã STRUTTURA DEI DATI - Ogni variabile √® un tassello della storia:\n")
glimpse(titanic_raw)

# Statistiche descrittive che rivelano pattern sociali
summary_stats <- summary(titanic_raw)
print(summary_stats)

# Analisi dei valori mancanti - anche ci√≤ che non sappiamo √® informativo
missing_analysis <- titanic_raw %>%
  summarise_all(~sum(is.na(.))) %>%
  gather(Variable, Missing_Count) %>%
  mutate(
    Missing_Percentage = round(Missing_Count / nrow(titanic_raw) * 100, 2),
    Interpretation = case_when(
      Variable == "Age" ~ "L'et√† era spesso non registrata accuratamente",
      Variable == "Cabin" ~ "I passeggeri di classe inferiore raramente avevano cabine assegnate",
      Variable == "Embarked" ~ "Porto d'imbarco quasi sempre documentato",
      TRUE ~ "Informazione generalmente disponibile"
    )
  ) %>%
  arrange(desc(Missing_Count))

missing_analysis %>%
  select(-Interpretation) %>%
  kable(
    caption = "üîç Analisi dei Valori Mancanti: Anche l'Assenza √® Informativa",
    col.names = c("Variabile", "N. Mancanti", "% Mancanti")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  row_spec(which(missing_analysis$Missing_Count > 0), background = "#ffe6e6")

cat("\nüí° INSIGHT CHIAVE: I valori mancanti non sono casuali - riflettono le disuguaglianze sociali dell'epoca!\n")
```

## Preprocessing Intelligente: Trasformare i Dati con Rigore Scientifico

**La fase di preprocessing √® cruciale nell'analisi Bayesiana** perch√©
ogni decisione influenza le nostre inferenze. Documentiamo
scrupolosamente ogni scelta per garantire riproducibilit√† e trasparenza.

```{r data-preprocessing}
# ============================================================================
# PREPROCESSING SCIENTIFICO: OGNI DECISIONE √à DOCUMENTATA E GIUSTIFICATA
# ============================================================================

cat("üîß PREPROCESSING INTELLIGENTE: Trasformazioni Guidate dalla Teoria\n\n")

# Preprocessing completo con documentazione dettagliata delle scelte metodologiche
titanic <- titanic_raw %>%
  mutate(
    # Variabile target: trasformazione in factor per chiarezza interpretativa
    Survived = factor(Survived, levels = c(0, 1), labels = c("No", "Yes")),
    
    # Classe passeggero: ordinale con 3a classe come baseline (referenza storica)
    # TEORIA: La stratificazione sociale era rigida nel 1912
    Pclass = factor(Pclass, levels = c("3", "2", "1"), ordered = TRUE),
    
    # Sesso: factor binario (forte predictor storico di sopravvivenza)
    Sex = factor(Sex),
    
    # STRATEGIA DI IMPUTAZIONE EMBARKED: Imputazione con moda
    # GIUSTIFICAZIONE: Southampton era il porto principale (>70% dei passeggeri)
    Embarked = fct_na_value_to_level(factor(Embarked), level = "S"),
    
    # STRATEGIA DI IMPUTAZIONE AGE: Mediana (robusta agli outliers)
    # ALTERNATIVA CONSIDERATA: Imputazione multipla (computazionalmente intensiva)
    Age_original = Age,
    Age = if_else(is.na(Age), median(Age, na.rm = TRUE), Age),
    Age_imputed = is.na(Age_original),
    
    # FEATURE ENGINEERING: Dimensione famiglia (teoria sociale della sopravvivenza)
    # IPOTESI: Famiglie medie hanno vantaggi di sopravvivenza (aiuto reciproco vs. difficolt√† di movimento)
    FamilySize = SibSp + Parch + 1,
    
    # Categorizzazione per interpretazione qualitativa
    FamilyCategory = case_when(
      FamilySize == 1 ~ "Solo",
      FamilySize %in% 2:4 ~ "Piccola",
      FamilySize >= 5 ~ "Grande"
    )
  )

# Documentazione trasparente delle scelte di preprocessing
cat("üìã DOCUMENTAZIONE PREPROCESSING:\n")
cat("üë• Age - Valori mancanti:", sum(is.na(titanic_raw$Age)), 
    "‚Üí imputati con mediana =", round(median(titanic$Age), 1), "anni\n")
cat("üö¢ Embarked - Valori mancanti:", sum(is.na(titanic_raw$Embarked)), 
    "‚Üí imputati con moda = 'Southampton'\n")
cat("üìä Nuove variabili create: FamilySize, FamilyCategory, Age_imputed\n")
cat("üéØ Strategia: Preprocessing conservativo per preservare variabilit√† originale\n\n")

# Analisi dell'impatto dell'imputazione
cat("üîç ANALISI IMPATTO IMPUTAZIONE:\n")
age_comparison <- data.frame(
  Statistica = c("Media", "Mediana", "Dev.Standard", "Min", "Max"),
  Originale = c(mean(titanic_raw$Age, na.rm=T), median(titanic_raw$Age, na.rm=T), 
               sd(titanic_raw$Age, na.rm=T), min(titanic_raw$Age, na.rm=T), 
               max(titanic_raw$Age, na.rm=T)),
  Dopo_Imputazione = c(mean(titanic$Age), median(titanic$Age), 
                      sd(titanic$Age), min(titanic$Age), max(titanic$Age))
) %>%
  mutate(Differenza_Assoluta = abs(Originale - Dopo_Imputazione))

age_comparison %>%
  kable(digits = 2, 
        caption = "Confronto Distribuzione Et√†: Prima e Dopo Imputazione") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

# Verifica post-preprocessing
cat("\n‚úÖ VERIFICA QUALIT√Ä DATI POST-PROCESSING:\n")
glimpse(titanic)
```

## Analisi Esplorativa Rivoluzionaria: I Dati Rivelano i loro Segreti

**L'analisi esplorativa in un contesto Bayesiano non √® solo
descrittiva - √® predittiva!** Ogni pattern che identifichiamo informa le
nostre prior e guida la costruzione del modello.

```{r advanced-eda, fig.height=12}
# ============================================================================
# ANALISI ESPLORATIVA AVANZATA: SCOPRIRE I PATTERN NASCOSTI NELLA STORIA
# ============================================================================

cat("üé® ANALISI ESPLORATIVA: Visualizzare la Storia attraverso i Dati\n\n")

# 1. DISTRIBUZIONE ET√Ä: La Demografia della Tragedia
p1 <- ggplot(titanic, aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = custom_colors[1], color = "white", alpha = 0.8) +
  geom_vline(xintercept = median(titanic$Age), linetype = "dashed", color = "red", linewidth = 1) +
  geom_vline(xintercept = mean(titanic$Age), linetype = "dotted", color = "blue", linewidth = 1) +
  annotate("text", x = median(titanic$Age) + 2, y = 50, 
           label = paste("Mediana =", round(median(titanic$Age), 1)), 
           color = "red", size = 3.5) +
  annotate("text", x = mean(titanic$Age) + 2, y = 45, 
           label = paste("Media =", round(mean(titanic$Age), 1)), 
           color = "blue", size = 3.5) +
  labs(title = "üìä Demografia del Titanic: Una Popolazione Giovane", 
       subtitle = "La distribuzione dell'et√† rivela una societ√† in viaggio",
       x = "Et√† (anni)", y = "Frequenza") +
  theme_minimal()

# 2. DISTRIBUZIONE TARIFFE: L'Economia della Disuguaglianza
p2 <- ggplot(titanic, aes(x = Fare + 0.1)) +  # +0.1 per gestire log(0)
  geom_histogram(bins = 40, fill = custom_colors[2], color = "white", alpha = 0.8) +
  scale_x_log10(labels = scales::dollar_format(prefix = "¬£")) +
  geom_vline(xintercept = median(titanic$Fare, na.rm = TRUE), 
             linetype = "dashed", color = "red", linewidth = 1) +
  labs(title = "üí∞ Economia del Titanic: Disuguaglianze Estreme", 
       subtitle = "Le tariffe riflettono la stratificazione sociale del 1912",
       x = "Tariffa (¬£, scala logaritmica)", y = "Frequenza") +
  theme_minimal()

# 3. SOPRAVVIVENZA PER CLASSE: Il Potere del Privilegio
survival_by_class <- titanic %>%
  group_by(Pclass, Survived) %>%
  summarise(n = n(), .groups = "drop") %>%
  group_by(Pclass) %>%
  mutate(prop = n / sum(n))

p3 <- ggplot(titanic, aes(x = Pclass, fill = Survived)) +
  geom_bar(position = "fill", alpha = 0.8) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = custom_colors[c(4, 3)], 
                   name = "Sopravvivenza", 
                   labels = c("Deceduto", "Sopravvissuto")) +
  labs(title = "‚öñÔ∏è Sopravvivenza per Classe: La Giustizia Sociale in Mare", 
       subtitle = "Il privilegio sociale si traduce in privilegi di sopravvivenza",
       x = "Classe del Passeggero", y = "Proporzione") +
  theme_minimal()

# 4. SOPRAVVIVENZA PER SESSO: Il Codice d'Onore Marittimo
p4 <- ggplot(titanic, aes(x = Sex, fill = Survived)) +
  geom_bar(position = "fill", alpha = 0.8) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = custom_colors[c(4, 3)], 
                   name = "Sopravvivenza", 
                   labels = c("Deceduto", "Sopravvissuto")) +
  labs(title = "üë©‚Äçüëß‚Äçüë¶ 'Women and Children First': Codice d'Onore in Azione", 
       subtitle = "Il principio marittimo salv√≤ vite femminili",
       x = "Sesso", y = "Proporzione") +
  theme_minimal()

# Combinazione dei primi quattro grafici
grid.arrange(p1, p2, p3, p4, ncol = 2)

# 5. ANALISI MULTIDIMENSIONALE: Interazioni Complesse
p5 <- ggplot(titanic, aes(x = Age, y = Fare + 0.1, color = Survived)) +
  geom_point(alpha = 0.6, size = 1.5) +
  scale_y_log10(labels = scales::dollar_format(prefix = "¬£")) +
  scale_color_manual(values = custom_colors[c(4, 3)], 
                    name = "Sopravvivenza") +
  facet_grid(rows = vars(Sex), cols = vars(Pclass)) +  # FIXED: Updated syntax
  labs(title = "üåê Analisi Multidimensionale: L'Intreccio di Et√†, Ricchezza e Privilegio", 
       subtitle = "Ogni pannello racconta una storia diversa di sopravvivenza",
       x = "Et√† (anni)", y = "Tariffa (¬£, scala logaritmica)") +
  theme_minimal()

# 6. EFFETTO FAMIGLIA: La Forza dei Legami
family_survival <- titanic %>%
  group_by(FamilyCategory, Survived) %>%
  summarise(n = n(), .groups = "drop") %>%
  group_by(FamilyCategory) %>%
  mutate(prop = n / sum(n),
         total = sum(n))

p6 <- ggplot(titanic, aes(x = FamilyCategory, fill = Survived)) +
  geom_bar(position = "fill", alpha = 0.8) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = custom_colors[c(4, 3)], 
                   name = "Sopravvivenza") +
  labs(title = "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Dimensione Famiglia: Cooperazione vs. Coordinazione", 
       subtitle = "Famiglie medie mostrano vantaggi di sopravvivenza ottimali",
       x = "Categoria Dimensione Famiglia", y = "Proporzione") +
  theme_minimal()

# Mostra analisi multidimensionale
print(p5)
print(p6)

# Statistiche esplorative chiave
cat("\nüìà INSIGHT ESPLORATIVI CRUCIALI:\n")
cat("üéØ Tasso sopravvivenza globale:", round(mean(titanic$Survived == "Yes") * 100, 1), "%\n")
cat("‚ôÄÔ∏è  Tasso sopravvivenza donne:", round(mean(titanic$Survived[titanic$Sex == "female"] == "Yes") * 100, 1), "%\n")
cat("‚ôÇÔ∏è  Tasso sopravvivenza uomini:", round(mean(titanic$Survived[titanic$Sex == "male"] == "Yes") * 100, 1), "%\n")
cat("ü•á Tasso sopravvivenza 1a classe:", round(mean(titanic$Survived[titanic$Pclass == "1"] == "Yes") * 100, 1), "%\n")
cat("ü•â Tasso sopravvivenza 3a classe:", round(mean(titanic$Survived[titanic$Pclass == "3"] == "Yes") * 100, 1), "%\n")
```

# Specifica del Modello Statistico: L'Architettura della Conoscenza Bayesiana

## Fondamenti Teorici: Perch√© la Regressione Logistica Gerarchica √® Perfetta

**La scelta del modello non √® casuale - √® il risultato di considerazioni
teoriche profonde:**

### 1. **Natura Binaria della Sopravvivenza**: Bernoulli come Distribuzione Naturale

La sopravvivenza √® intrinsecamente binaria (vivo/morto), rendendo la
**distribuzione di Bernoulli la scelta teorica perfetta**. La funzione
di link logit trasforma le probabilit√† nell'intero asse reale,
permettendo una modellazione lineare dei predittori.

### 2. **Struttura Gerarchica**: Catturare l'Eterogeneit√† Non Osservata

I passeggeri non sono osservazioni indipendenti - sono **raggruppati per
porto d'imbarco**, creando una struttura naturalmente gerarchica. Gli
effetti random catturano l'eterogeneit√† non osservata tra i porti
(differenze culturali, procedure d'imbarco, composizione sociale).

## Giustificazione Rigorosa delle Distribuzioni a Priori

**Le prior non sono scelte arbitrarie - sono decisioni metodologiche
ponderate basate su principi statistici consolidati:**

### Coefficienti di Regressione: Œ≤_k \~ Normal(0, 10¬≤)

**Motivazione Epistemologica:** - **Principio di Massima Entropia**: La
distribuzione normale massimizza l'entropia data la varianza,
rappresentando il massimo stato di "ignoranza informata" -
**Interpretazione Pratica**: Permette odds ratios tra exp(-30) ‚âà 10‚Åª¬π¬≥ e
exp(30) ‚âà 10¬π¬≥, coprendo tutto lo spettro realisticamente possibile -
**Regolarizzazione Implicita**: Previene overfitting senza essere
eccessivamente restrittiva - **Robustezza**: Sufficientemente vaga da
non dominare i dati quando questi sono informativi

**Alternativa Considerata:** Normal(0, 2.5¬≤) seguendo Gelman et al.
(2008), pi√π conservativa ma potenzialmente troppo restrittiva per
effetti realmente grandi.

### Random Effects: œÉ_u \~ Half-Cauchy(0, 5)

**Rivoluzione Teorica di Gelman (2006):** - **Code Pesanti**: La
distribuzione Half-Cauchy permette grande variabilit√† tra gruppi quando
supportata dai dati, ma si comporta conservativamente quando i dati
suggeriscono poca variabilit√† - **Robustezza con Pochi Gruppi**: A
differenza delle prior inverse-gamma tradizionali, funziona bene anche
con pochi gruppi (nel nostro caso, 3 porti) - **Reference Standard**: √à
diventata la scelta standard nella letteratura Bayesiana moderna per
parametri di varianza

## Formulazione Matematica Elegante

Il nostro modello rappresenta un **capolavoro di eleganza matematica e
interpretabilit√† sostantiva**:

$$\begin{aligned}
y_i &\sim \text{Bernoulli}(p_i) && \text{[Sopravvivenza binaria]} \\[0.4em]
\text{logit}(p_i) &= \boldsymbol{X_i}^T\boldsymbol{\beta} + u_{j[i]} && \text{[Link logit + effetti gerarchici]} \\[0.4em]
\text{dove } \boldsymbol{X_i}^T\boldsymbol{\beta} &= \beta_0 + \beta_{\text{female}} \cdot \mathbb{I}(\text{Sex}_i = \text{female}) && \text{[Effetto del sesso]} \\
&\quad + \beta_{\text{age}} \cdot \text{Age}_i^* + \beta_{\text{fare}} \cdot \text{Fare}_i^* && \text{[Effetti continui]} \\
&\quad + \beta_{\text{fam}} \cdot \text{FamSize}_i^* + \beta_{\text{fam¬≤}} \cdot (\text{FamSize}_i^*)^2 && \text{[Effetto non-lineare famiglia]} \\
&\quad + \beta_{\text{class1}} \cdot \mathbb{I}(\text{Pclass}_i = 1) && \text{[Prima classe vs. terza]} \\
&\quad + \beta_{\text{class2}} \cdot \mathbb{I}(\text{Pclass}_i = 2) && \text{[Seconda classe vs. terza]} \\[0.4em]
u_j &\sim \mathcal{N}(0, \sigma_u^2), \quad j \in \{\text{Southampton, Cherbourg, Queenstown}\} && \text{[Random intercepts]} \\[0.4em]
\boldsymbol{\beta} &\sim \mathcal{N}(\mathbf{0}, 10^2 \mathbf{I}) && \text{[Prior debolmente informative]} \\[0.4em]
\sigma_u &\sim \text{Half-Cauchy}(0, 5) && \text{[Prior robusta per varianza]}
\end{aligned}$$

**Note Metodologiche Cruciali:** - **Standardizzazione**: Le variabili
continue (Age*, Fare*, FamSize\*) sono standardizzate per migliorare la
convergenza MCMC e rendere le prior pi√π interpretabili - **Baseline**:
La terza classe serve come categoria di riferimento (storicamente la pi√π
numerosa) - **Non-linearit√†**: Il termine quadratico per FamilySize
cattura effetti ottimali (ipotesi di cooperazione familiare ottimale)

## Obiettivi Inferenziali Ambiziosi

La nostra analisi non si limita alla stima - mira a **rivoluzionare la
comprensione** dell'evento storico:

1.  **Quantificazione Probabilistica Precisa**: Ogni coefficiente viene
    stimato con la sua distribuzione completa a posteriori
2.  **Decomposizione della Variabilit√†**: Separare l'effetto individuale
    da quello del porto d'imbarco
3.  **Predizione Affidabile**: Sviluppare capacit√† predittive per
    scenari controfattuali
4.  **Validazione Rigorosa**: Dimostrare l'affidabilit√† attraverso tutti
    i check possibili
5.  **Confronto Metodologico**: Stabilire la superiorit√† dell'approccio
    Bayesiano

```{r model-data-preparation}
# ============================================================================
# PREPARAZIONE DATI PER JAGS: TRASFORMAZIONE OTTIMALE PER MCMC
# ============================================================================

cat("üîß PREPARAZIONE DATI PER ANALISI BAYESIANA\n")
cat("üí° Ogni trasformazione √® ottimizzata per la convergenza MCMC!\n\n")

# Preparazione lista dati con nomi descrittivi e trasformazioni ottimali
data_list <- list(
  # Dimensioni del problema
  N            = nrow(titanic),
  
  # Variabile response (0/1 per compatibilit√† JAGS)
  y            = as.numeric(titanic$Survived == "Yes"),
  
  # Variabili continue STANDARDIZZATE (crucial per convergenza MCMC)
  age_std      = as.numeric(scale(titanic$Age)),
  fare_std     = as.numeric(scale(titanic$Fare)),
  family_size_std = as.numeric(scale(titanic$FamilySize)),
  family_size_sq_std = as.numeric(scale(titanic$FamilySize^2)),
  
  # Variabili binarie (codifica 0/1)
  female       = as.integer(titanic$Sex == "female"),
  class_1      = as.integer(titanic$Pclass == "1"),
  class_2      = as.integer(titanic$Pclass == "2"),
  # class_3 √® la baseline (omessa per evitare collinearit√†)
  
  # Struttura gerarchica
  embarked_idx = as.integer(titanic$Embarked),
  n_embarked   = nlevels(titanic$Embarked)
)

# Verifica della preparazione dati
cat("üìä STRUTTURA DATI PREPARATI:\n")
str(data_list)

cat("\n‚úÖ VERIFICHE DI QUALIT√Ä:\n")
cat("üìà Range et√† standardizzata:", round(range(data_list$age_std), 2), "\n")
cat("üí∞ Range tariffa standardizzata:", round(range(data_list$fare_std), 2), "\n")
cat("üë• Range famiglia standardizzata:", round(range(data_list$family_size_std), 2), "\n")
cat("üö¢ Porti d'imbarco:", levels(titanic$Embarked), "\n")
cat("üéØ Tasso sopravvivenza:", round(mean(data_list$y) * 100, 1), "%\n")
```

# Implementazione MCMC: L'Arte della Simulazione Bayesiana

## Modello Base: Il Cuore dell'Analisi Gerarchica

**Il modello base rappresenta il nostro framework teorico principale**,
implementato con precisione chirurgica in JAGS. Ogni riga di codice
riflette decenni di sviluppo nella metodologia Bayesiana.

```{r base-model-implementation, cache=FALSE}
# ============================================================================
# MODELLO BASE: REGRESSIONE LOGISTICA GERARCHICA MAGISTRALE
# ============================================================================

# Definizione del modello in linguaggio JAGS
# NOTA: JAGS usa precisione (1/varianza) invece di varianza nelle distribuzioni normali
model_base_string <- "
model {
  # ========================================
  # LIKELIHOOD: IL CUORE PROBABILISTICO
  # ========================================
  for(i in 1:N) {
    # Distribuzione di Bernoulli per la sopravvivenza
    y[i] ~ dbern(p[i])
    
    # Trasformazione logit: da probabilit√† a scala lineare
    logit(p[i]) <- beta0 + 
                   beta_female * female[i] + 
                   beta_age * age_std[i] + 
                   beta_fare * fare_std[i] + 
                   beta_family * family_size_std[i] + 
                   beta_family_sq * family_size_sq_std[i] + 
                   beta_class1 * class_1[i] + 
                   beta_class2 * class_2[i] + 
                   u_embarked[embarked_idx[i]]
  }
  
  # ========================================
  # PRIORS: LA SAGGEZZA A PRIORI
  # ========================================
  
  # Prior per i coefficienti di regressione
  # dnorm(media, precisione) dove precisione = 1/varianza
  # Precisione = 0.01 ‚Üí Varianza = 100 ‚Üí Dev.Std = 10
  beta0        ~ dnorm(0, 0.01)  # Intercetta
  beta_female  ~ dnorm(0, 0.01)  # Effetto sesso (female vs male)
  beta_age     ~ dnorm(0, 0.01)  # Effetto et√† (standardizzata)
  beta_fare    ~ dnorm(0, 0.01)  # Effetto tariffa (standardizzata)
  beta_family  ~ dnorm(0, 0.01)  # Effetto dimensione famiglia (lineare)
  beta_family_sq ~ dnorm(0, 0.01)  # Effetto dimensione famiglia (quadratico)
  beta_class1  ~ dnorm(0, 0.01)  # Prima classe vs terza classe
  beta_class2  ~ dnorm(0, 0.01)  # Seconda classe vs terza classe
  
  # ========================================
  # RANDOM EFFECTS: CATTURARE L'ETEROGENEIT√Ä
  # ========================================
  
  # Random intercepts per porto d'imbarco
  for(j in 1:n_embarked) { 
    u_embarked[j] ~ dnorm(0, tau_u) 
  }
  
  # Prior per il parametro di varianza (Half-Cauchy via trasformazione)
  tau_u <- pow(sigma_u, -2)  # Conversione da deviazione standard a precisione
  sigma_u ~ dt(0, pow(5, -2), 1) T(0,)  # Half-Cauchy(0, 5) troncata
}
"

cat("üöÄ INIZIALIZZAZIONE MODELLO BASE: Architettura Bayesiana in Azione\n")

# FIXED: Clear any existing JAGS models and start fresh
if(exists("mod_base")) rm(mod_base)
if(exists("samples_base")) rm(samples_base)

# Compilazione e inizializzazione del modello
set.seed(42)  # Riproducibilit√† guarantita
mod_base <- jags.model(
  textConnection(model_base_string), 
  data = data_list, 
  n.chains = 4,  # 4 catene per diagnostica robusta
  n.adapt = 5000,  # Periodo di adattamento per ottimizzazione
  quiet = TRUE
)

cat("‚ö° Modello compilato con successo! Iniziando burn-in esteso...\n")

# Burn-in esteso per garantire convergenza dalla distribuzione stazionaria
update(mod_base, n.iter = 12000)

cat("üéØ Burn-in completato! Iniziando campionamento produttivo...\n")

# Campionamento con parametri ottimizzati per qualit√† ed efficienza
samples_base <- coda.samples(
  mod_base,
  variable.names = c("beta0", "beta_female", "beta_age", "beta_fare",
                     "beta_family", "beta_family_sq", "beta_class1", 
                     "beta_class2", "sigma_u", "u_embarked"),
  n.iter = 30000,  # Campionamento esteso
  thin = 20        # Thinning per ridurre autocorrelazione
)

cat("‚úÖ Campionamento base completato: 4 catene √ó 30,000 iterazioni (thinned) = 6,000 campioni totali\n")
```

## Modello Alternativo: Esplorando le Interazioni Sociali

**Il modello alternativo esplora se le interazioni sesso-classe
catturano dinamiche sociali pi√π complesse** della crisi. Questa √®
l'essenza della selezione di modelli Bayesiana!

```{r alternative-model-implementation, cache=FALSE}
# ============================================================================
# MODELLO ALTERNATIVO: INTERAZIONI SESSO-CLASSE NELL'EMERGENZA
# ============================================================================

cat("üî¨ MODELLO ALTERNATIVO: Esplorando Interazioni Sociali Complesse\n")
cat("üí≠ IPOTESI: Le donne di classe superiore avevano vantaggi addizionali?\n\n")

# Modello con termini di interazione sesso √ó classe
model_alt_string <- "
model {
  # ========================================
  # LIKELIHOOD ESTESA: CATTURARE INTERAZIONI SOCIALI
  # ========================================
  for(i in 1:N) {
    y[i] ~ dbern(p[i])
    
    # Linear predictor con termini di interazione
    logit(p[i]) <- beta0 + 
                   beta_female * female[i] + 
                   beta_age * age_std[i] + 
                   beta_fare * fare_std[i] + 
                   beta_family * family_size_std[i] + 
                   beta_family_sq * family_size_sq_std[i] + 
                   beta_class1 * class_1[i] + 
                   beta_class2 * class_2[i] + 
                   # NUOVI TERMINI: Interazioni sesso √ó classe
                   beta_int_fem_c1 * female[i] * class_1[i] +
                   beta_int_fem_c2 * female[i] * class_2[i] +
                   u_embarked[embarked_idx[i]]
  }
  
  # ========================================
  # PRIORS: STESSE ASSUNZIONI + NUOVI PARAMETRI
  # ========================================
  
  # Prior identiche per parametri esistenti
  beta0 ~ dnorm(0, 0.01)
  beta_female ~ dnorm(0, 0.01)
  beta_age ~ dnorm(0, 0.01)
  beta_fare ~ dnorm(0, 0.01)
  beta_family ~ dnorm(0, 0.01)
  beta_family_sq ~ dnorm(0, 0.01)
  beta_class1 ~ dnorm(0, 0.01)
  beta_class2 ~ dnorm(0, 0.01)
  
  # Prior per i NUOVI termini di interazione
  beta_int_fem_c1 ~ dnorm(0, 0.01)  # Donne √ó Prima classe
  beta_int_fem_c2 ~ dnorm(0, 0.01)  # Donne √ó Seconda classe
  
  # Random effects identici
  for(j in 1:n_embarked) { 
    u_embarked[j] ~ dnorm(0, tau_u) 
  }
  
  tau_u <- pow(sigma_u, -2)
  sigma_u ~ dt(0, pow(5, -2), 1) T(0,)
}
"

# FIXED: Clear any existing alternative models
if(exists("mod_alt")) rm(mod_alt)
if(exists("samples_alt")) rm(samples_alt)

# Compilazione modello alternativo
mod_alt <- jags.model(
  textConnection(model_alt_string), 
  data = data_list, 
  n.chains = 4, 
  n.adapt = 5000, 
  quiet = TRUE
)

cat("üîÑ Burn-in modello alternativo...\n")
update(mod_alt, n.iter = 12000)

cat("üìä Campionamento modello con interazioni...\n")
samples_alt <- coda.samples(
  mod_alt,
  variable.names = c("beta0", "beta_female", "beta_age", "beta_fare",
                     "beta_family", "beta_family_sq", "beta_class1", 
                     "beta_class2", "beta_int_fem_c1", "beta_int_fem_c2",
                     "sigma_u", "u_embarked"),
  n.iter = 30000,
  thin = 20
)

cat("‚úÖ Entrambi i modelli pronti per l'analisi comparativa!\n")
```

# Risultati Inferenziali: Le Distribuzioni a Posteriori Rivelano la Verit√†

## Sommario delle Distribuzioni a Posteriori: La Sintesi della Conoscenza

**Ogni distribuzione a posteriori rappresenta tutto ci√≤ che sappiamo su
un parametro dopo aver osservato i dati.** Questo √® il cuore della
rivoluzione Bayesiana!

```{r posterior-summary}
# ============================================================================
# ANALISI POSTERIORI: LA SINTESI DELLA CONOSCENZA BAYESIANA
# ============================================================================

cat("üìä DISTRIBUZIONI A POSTERIORI: Il Verdetto dei Dati\n")
cat("üéØ Ogni numero racconta una storia di sopravvivenza...\n\n")

# Selezione parametri principali per l'analisi
main_params <- c("beta0", "beta_female", "beta_age", "beta_fare",
                 "beta_family", "beta_family_sq", "beta_class1", 
                 "beta_class2", "sigma_u")

# Estrazione sommario completo delle posteriori
posterior_summary <- summary(samples_base[, main_params])

# Creazione tabella elegante e informativa
posterior_table <- data.frame(
  Parameter = rownames(posterior_summary$statistics),
  Mean = round(posterior_summary$statistics[, "Mean"], 3),
  SD = round(posterior_summary$statistics[, "SD"], 3),
  CI_2.5 = round(posterior_summary$quantiles[, "2.5%"], 3),
  CI_97.5 = round(posterior_summary$quantiles[, "97.5%"], 3)
) %>%
  mutate(
    # Significativit√† Bayesiana: L'intervallo di credibilit√† esclude lo zero?
    Significant = ifelse(sign(CI_2.5) == sign(CI_97.5), "‚úÖ", "‚ùì"),
    # Interpretazione qualitativa dell'effetto
    Effect_Size = case_when(
      abs(Mean) < 0.2 ~ "Piccolo",
      abs(Mean) < 0.5 ~ "Moderato", 
      abs(Mean) < 1.0 ~ "Grande",
      TRUE ~ "Molto Grande"
    )
  )

# Tabella formattata con stile professionale
posterior_table %>%
  select(-Effect_Size) %>%
  kable(
    caption = "üéØ Distribuzioni a Posteriori - Modello Base: La Verit√† Statistica sui Fattori di Sopravvivenza",
    col.names = c("Parametro", "Media Posteriore", "Dev. Std.", "CI 2.5%", "CI 97.5%", "Significativo"),
    align = c('l', 'c', 'c', 'c', 'c', 'c')
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE) %>%
  footnote(general = "‚úÖ = Intervallo di credibilit√† al 95% non include zero; ‚ùì = Include zero",
           general_title = "Legenda Significativit√† Bayesiana:") %>%
  row_spec(which(posterior_table$Significant == "‚úÖ"), background = "#e6ffe6") %>%
  row_spec(which(posterior_table$Significant == "‚ùì"), background = "#fff2e6")

cat("\nüîç INTERPRETAZIONE RAPIDA DELLA SIGNIFICATIVIT√Ä:\n")
significant_params <- posterior_table$Parameter[posterior_table$Significant == "‚úÖ"]
cat("üìà Effetti statisticamente significativi:", paste(significant_params, collapse = ", "), "\n")
cat("üìä Numero di parametri significativi:", length(significant_params), "su", nrow(posterior_table), "\n")
```

## Interpretazione Sostantiva: Trasformare Numeri in Storie Umane

**L'odds ratio √® il linguaggio universale per interpretare i modelli
logistici.** Ogni odds ratio ci dice quante volte aumentano (o
diminuiscono) le possibilit√† di sopravvivenza.

```{r coefficient-interpretation}
# ============================================================================
# INTERPRETAZIONE IN ODDS RATIOS: DAI COEFFICIENTI ALLE STORIE UMANE
# ============================================================================

cat("üé≠ TRASFORMAZIONE IN ODDS RATIOS: Rendere i Numeri Comprensibili\n")
cat("üí° Ogni odds ratio racconta quante volte cambiano le possibilit√† di sopravvivenza\n\n")

# Calcolo odds ratios dalle medie posteriori
posterior_means <- colMeans(as.matrix(samples_base[, main_params]))
odds_ratios <- exp(posterior_means[grep("beta", names(posterior_means))])

# Calcolo intervalli di credibilit√† per gli odds ratios
or_ci_lower <- exp(posterior_table$CI_2.5[1:8])
or_ci_upper <- exp(posterior_table$CI_97.5[1:8])

# Creazione dataset interpretativo completo
interpretation_data <- data.frame(
  Variable = c("Baseline (Uomo, 3a classe)", "Essere Donna", "Et√† (+1 dev.std)", 
               "Tariffa (+1 dev.std)", "Dimensione Famiglia (+1 dev.std)", 
               "Dimensione Famiglia¬≤ (+1 dev.std)", "1a vs 3a Classe", "2a vs 3a Classe"),
  Odds_Ratio = round(c(exp(posterior_means[1]), odds_ratios[-1]), 2),
  CI_Lower = round(c(exp(posterior_table$CI_2.5[1]), or_ci_lower[-1]), 2),
  CI_Upper = round(c(exp(posterior_table$CI_97.5[1]), or_ci_upper[-1]), 2),
  Interpretation = c(
    "Odds di base per il gruppo di riferimento",
    paste("Le donne hanno", round(odds_ratios[2], 1), "volte maggiori possibilit√† di sopravvivere"),
    ifelse(odds_ratios[3] < 1, 
           paste("Ogni aumento dell'et√† riduce le odds del", round((1-odds_ratios[3])*100, 0), "%"),
           paste("Et√† maggiore aumenta le odds del", round((odds_ratios[3]-1)*100, 0), "%")),
    paste("Tariffe pi√π alte aumentano le odds del", round((odds_ratios[4]-1)*100, 0), "%"),
    ifelse(odds_ratios[5] > 1,
           paste("Famiglie pi√π grandi aumentano le odds del", round((odds_ratios[5]-1)*100, 0), "%"),
           paste("Famiglie pi√π grandi riducono le odds del", round((1-odds_ratios[5])*100, 0), "%")),
    ifelse(odds_ratios[6] < 1, "Effetto quadratico negativo (optimum familiare)", "Effetto quadratico positivo"),
    paste("1a classe ha", round(odds_ratios[7], 1), "volte maggiori possibilit√† vs 3a classe"),
    paste("2a classe ha", round(odds_ratios[8], 1), "volte maggiori possibilit√† vs 3a classe")
  )
)

# Tabella odds ratios con interpretazione
interpretation_data %>%
  select(-Interpretation) %>%
  kable(
    caption = "üéØ Odds Ratios e Intervalli di Credibilit√†: L'Impatto Quantificato di Ogni Fattore",
    col.names = c("Fattore", "Odds Ratio", "CI Inf. (2.5%)", "CI Sup. (97.5%)"),
    align = c('l', 'c', 'c', 'c')
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE) %>%
  footnote(general = "Odds Ratio > 1: aumenta sopravvivenza; < 1: diminuisce sopravvivenza",
           general_title = "Interpretazione:") %>%
  row_spec(which(interpretation_data$Odds_Ratio > 1), background = "#e6ffe6") %>%
  row_spec(which(interpretation_data$Odds_Ratio < 1), background = "#ffe6e6")

# Stampa dei risultati chiave pi√π emozionanti
cat("\nüéâ === I RISULTATI PI√ô DRAMMATICI ===\n")
cat("üë© EFFETTO SESSO: Le donne avevano probabilit√†", 
    round((odds_ratios[2] - 1) * 100, 0), "% maggiori di sopravvivere!\n")
cat("ü•á EFFETTO CLASSE: La 1a classe aveva probabilit√†", 
    round((odds_ratios[7] - 1) * 100, 0), "% maggiori vs. 3a classe!\n")
cat("üë¥ EFFETTO ET√Ä: Ogni anno di et√† in pi√π riduceva le possibilit√† di circa", 
    round((1 - exp(posterior_means[3] / sd(titanic$Age))) * 100, 1), "%\n")
cat("üí∞ EFFETTO RICCHEZZA: Tariffe pi√π alte correlavano con maggiore sopravvivenza\n")
cat("üë®‚Äçüë©‚Äçüëß‚Äçüë¶ EFFETTO FAMIGLIA: Dinamica complessa - optimum per famiglie medie\n")

# Probabilit√† condizionali illustrative
cat("\nüìä === PROBABILIT√Ä DI SOPRAVVIVENZA PREDETTE ===\n")
# Donna, 1a classe, et√† media
prob_woman_1st <- plogis(posterior_means[1] + posterior_means[2] + posterior_means[7])
cat("üëë Donna, 1a classe, et√† media:", round(prob_woman_1st * 100, 1), "%\n")

# Uomo, 3a classe, et√† media
prob_man_3rd <- plogis(posterior_means[1])
cat("üë® Uomo, 3a classe, et√† media:", round(prob_man_3rd * 100, 1), "%\n")

cat("‚öñÔ∏è Differenza drammatica:", round((prob_woman_1st - prob_man_3rd) * 100, 1), "punti percentuali!\n")
```

# Diagnostica di Convergenza: Garantire l'Affidabilit√† Scientifica

**La diagnostica di convergenza √® il controllo qualit√† della nostra
analisi Bayesiana.** Senza convergenza, le nostre inferenze non hanno
valore scientifico!

```{r enhanced-convergence-diagnostics, fig.height=14}
# ============================================================================
# DIAGNOSTICA MCMC AVANZATA: GARANZIA DI QUALIT√Ä SCIENTIFICA
# ============================================================================

cat("üî¨ DIAGNOSTICA CONVERGENZA: Validazione Rigorosa dell'Analisi MCMC\n")
cat("üéØ Standard professionale: RÃÇ < 1.05 e ESS > 400 per tutti i parametri\n\n")

# Configurazione tema bayesplot
color_scheme_set("viridis")

# 1. TRACE PLOTS: Visualizzare il "random walk" delle catene
cat("üìà TRACE PLOTS: Visualizzando il Cammino delle Catene MCMC\n")
trace_plot1 <- mcmc_trace(samples_base, pars = main_params[1:4]) +
  ggtitle("üîç Trace Plots - Parametri Principali (1-4)") +
  labs(subtitle = "Ogni linea rappresenta una catena MCMC indipendente") +
  theme(legend.position = "none")

trace_plot2 <- mcmc_trace(samples_base, pars = main_params[5:8]) +
  ggtitle("üîç Trace Plots - Parametri Principali (5-8)") +
  labs(subtitle = "Convergenza = linee che si mescolano orizzontalmente") +
  theme(legend.position = "none")

print(trace_plot1)
print(trace_plot2)

# 2. AUTOCORRELAZIONE: Misurare l'indipendenza dei campioni
cat("\nüîÑ AUTOCORRELAZIONE: Verificando l'Indipendenza dei Campioni\n")
acf_plot <- mcmc_acf(samples_base, pars = main_params[1:6]) +
  ggtitle("üìä Autocorrelazione delle Catene MCMC") +
  labs(subtitle = "Declino rapido = buona indipendenza tra campioni")

print(acf_plot)

# 3. DENSIT√Ä POSTERIORI: La forma della conoscenza
cat("\nüé® DENSIT√Ä POSTERIORI: Visualizzando la Forma della Conoscenza\n")
density_plot <- mcmc_areas(samples_base, pars = main_params[2:6]) +
  ggtitle("üåä Densit√† a Posteriori - Effetti Principali") +
  labs(subtitle = "L'area sotto ogni curva rappresenta la probabilit√†")

print(density_plot)
```

```{r convergence-statistics}
# ============================================================================
# STATISTICHE DI CONVERGENZA QUANTITATIVE
# ============================================================================

cat("üìä STATISTICHE QUANTITATIVE DI CONVERGENZA\n\n")

# Calcolo R-hat (Gelman-Rubin diagnostic)
rhat_values <- gelman.diag(samples_base[, main_params], multivariate = FALSE)$psrf

# Calcolo Effective Sample Size
ess_values <- effectiveSize(samples_base[, main_params])

# Creazione tabella diagnostica completa
convergence_diagnostics <- data.frame(
  Parameter = names(ess_values),
  R_hat = round(rhat_values[, 1], 4),
  R_hat_Upper_CI = round(rhat_values[, 2], 4),
  ESS = round(ess_values, 0),
  ESS_per_iter = round(ess_values / (30000/20 * 4), 3),  # 4 catene, 30000 iter, thin=20
  Total_samples = rep(4 * (30000/20), length(ess_values)),
  Efficiency = round(ess_values / (4 * (30000/20)) * 100, 1),
  Convergence_Status = case_when(
    rhat_values[, 1] < 1.01 & ess_values > 1000 ~ "üü¢ Eccellente",
    rhat_values[, 1] < 1.05 & ess_values > 400 ~ "üü° Buona", 
    rhat_values[, 1] < 1.1 & ess_values > 100 ~ "üü† Accettabile",
    TRUE ~ "üî¥ Problematica"
  )
) %>%
  arrange(desc(ESS))

# Tabella elegante con codici colore
convergence_diagnostics %>%
  select(Parameter, R_hat, ESS, ESS_per_iter, Efficiency, Convergence_Status) %>%
  kable(
    caption = "üî¨ Diagnostica di Convergenza MCMC: Validazione Quantitativa della Qualit√†",
    col.names = c("Parametro", "RÃÇ", "ESS", "ESS/iter", "Efficienza (%)", "Status"),
    align = c('l', 'c', 'c', 'c', 'c', 'c')
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(
    general = c("RÃÇ < 1.05: convergenza soddisfacente", 
                "ESS > 400: campionamento efficace",
                "Efficienza = % di campioni indipendenti"),
    general_title = "Criteri di Qualit√†:"
  ) %>%
  row_spec(which(str_detect(convergence_diagnostics$Convergence_Status, "Eccellente")), 
           background = "#e6ffe6") %>%
  row_spec(which(str_detect(convergence_diagnostics$Convergence_Status, "Buona")), 
           background = "#fff9e6")

# Verifica convergenza globale
all_converged <- all(rhat_values[, 1] < 1.05 & ess_values > 400)
mean_rhat <- mean(rhat_values[, 1])
min_ess <- min(ess_values)

cat("\nüéØ === VERDETTO FINALE SULLA CONVERGENZA ===\n")
cat("‚úÖ Convergenza globale raggiunta:", ifelse(all_converged, "S√å! üéâ", "NO ‚ö†Ô∏è"), "\n")
cat("üìä RÃÇ medio:", round(mean_rhat, 4), "(target: < 1.05)\n")
cat("üìà ESS minimo:", round(min_ess, 0), "(target: > 400)\n")
cat("‚≠ê Efficienza media:", round(mean(convergence_diagnostics$Efficiency), 1), "%\n")

if (all_converged) {
  cat("üèÜ RISULTATO: Analisi di qualit√† eccellente - procediamo con confidenza!\n")
} else {
  problematic_params <- names(ess_values)[rhat_values[, 1] >= 1.05 | ess_values <= 400]
  cat("‚ö†Ô∏è  Parametri che richiedono attenzione:", paste(problematic_params, collapse = ", "), "\n")
}
```

# Confronto tra Modelli: La Competizione Scientifica

**Il confronto tra modelli √® l'essenza della scienza Bayesiana.** Usiamo
il DIC (Deviance Information Criterion) per bilanciare bont√† di
adattamento e complessit√†.

```{r model-comparison, cache=FALSE}
# ============================================================================
# CONFRONTO MODELLI: LA COMPETIZIONE PER LA VERIT√Ä SCIENTIFICA
# ============================================================================

cat("üèÅ CONFRONTO MODELLI: Quale Cattura Meglio la Realt√†?\n")
cat("üéØ DIC (Deviance Information Criterion): Bilancia fit e complessit√†\n\n")

# Calcolo DIC per entrambi i modelli con campionamento robusto
cat("üìä Calcolando DIC per modello base...\n")
dic_base <- dic.samples(mod_base, n.iter = 20000, type = "pD")

cat("üìä Calcolando DIC per modello alternativo...\n")
dic_alt <- dic.samples(mod_alt, n.iter = 20000, type = "pD")

# Estrazione componenti DIC
dic_base_deviance <- sum(dic_base$deviance)
dic_base_penalty <- sum(dic_base$penalty)
dic_base_value <- dic_base_deviance + dic_base_penalty

dic_alt_deviance <- sum(dic_alt$deviance)
dic_alt_penalty <- sum(dic_alt$penalty)
dic_alt_value <- dic_alt_deviance + dic_alt_penalty

# Differenza DIC (quanto conta l'aggiunta di interazioni?)
delta_dic <- dic_alt_value - dic_base_value

# Tabella comparativa elegante
model_comparison <- data.frame(
  Model = c("üîπ Base (senza interazioni)", "üî∏ Alternativo (con interazioni sesso√óclasse)"),
  Deviance = c(dic_base_deviance, dic_alt_deviance),
  pD = c(dic_base_penalty, dic_alt_penalty),
  DIC = c(dic_base_value, dic_alt_value),
  Delta_DIC = c(0, delta_dic),
  Rank = c(ifelse(delta_dic > 0, 1, 2), ifelse(delta_dic > 0, 2, 1))
) %>%
  arrange(DIC)

model_comparison %>%
  kable(
    caption = "üèÜ Confronto tra Modelli tramite DIC: La Competizione per la Migliore Spiegazione",
    digits = 2,
    col.names = c("Modello", "Devianza", "pD (penalit√†)", "DIC", "ŒîDIC", "Ranking")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(
    general = c("DIC pi√π basso = modello migliore", 
                "pD = penalit√† per complessit√†",
                "ŒîDIC > 5: differenza sostanziale"),
    general_title = "Interpretazione DIC:"
  ) %>%
  row_spec(1, background = "#e6ffe6", bold = TRUE)  # Evidenzia il vincitore

# Interpretazione evidence strength (Spiegelhalter et al.)
evidence_interpretation <- case_when(
  abs(delta_dic) <= 2 ~ "üìä Evidenza debole - modelli sostanzialmente equivalenti",
  abs(delta_dic) <= 5 ~ "üìà Evidenza moderata",
  abs(delta_dic) <= 10 ~ "üìä Evidenza forte",
  TRUE ~ "üéØ Evidenza molto forte"
)

cat("\nüé≠ === VERDETTO DEL CONFRONTO MODELLI ===\n")
cat("üìä ŒîDIC (Alternativo - Base):", round(delta_dic, 2), "\n")
cat("üîç Interpretazione della forza dell'evidenza:", evidence_interpretation, "\n")

if (delta_dic < -2) {
  cat("üèÜ VINCITORE: Modello con interazioni sesso√óclasse!\n")
  cat("üí° SIGNIFICATO: Le interazioni sociali catturano dinamiche importanti\n")
  cat("üìà Le donne di classe superiore avevano vantaggi addizionali oltre agli effetti principali\n")
} else if (delta_dic > 2) {
  cat("üèÜ VINCITORE: Modello base (senza interazioni)!\n")
  cat("üí° SIGNIFICATO: Gli effetti principali spiegano sufficientemente i dati\n")
  cat("üìà Le interazioni aggiungono complessit√† senza migliorare sostanzialmente il fit\n")
} else {
  cat("ü§ù PAREGGIO: I modelli sono sostanzialmente equivalenti\n")
  cat("üí° SIGNIFICATO: Scegliamo il pi√π semplice per parsimonia\n")
}

# Selezione del modello migliore per analisi successive
best_model_name <- if_else(delta_dic < 0, "alternativo", "base")
best_samples <- if_else(delta_dic < 0, list(samples_alt), list(samples_base))[[1]]
best_model_object <- if_else(delta_dic < 0, list(mod_alt), list(mod_base))[[1]]

cat("\nüéØ MODELLO SELEZIONATO per analisi successive:", toupper(best_model_name), "\n")
cat("üìã Questo modello verr√† utilizzato per PPC, predizioni e confronti\n")
```

# Posterior Predictive Checks: Validare la Capacit√† del Modello

**I Posterior Predictive Checks (PPC) sono il test finale del nostro
modello.** Se il modello √® buono, dovrebbe essere capace di rigenerare i
pattern osservati nei dati reali!

```{r enhanced-ppc, fig.height=12}
# ============================================================================
# POSTERIOR PREDICTIVE CHECKS: IL TEST FINALE DELLA VALIDIT√Ä
# ============================================================================

cat("üîÆ POSTERIOR PREDICTIVE CHECKS: Pu√≤ il Nostro Modello Ricreare la Realt√†?\n")
cat("üéØ Se il modello √® valido, dovrebbe rigenerare i pattern osservati!\n\n")

# Funzione sofisticata per generare dati replicati
generate_replicated_data <- function(samples_matrix, data_list, model_type = "base") {
  
  cat("‚öôÔ∏è Generando", nrow(samples_matrix), "dataset replicati...\n")
  
  n_samples <- nrow(samples_matrix)
  n_obs <- data_list$N
  y_rep <- matrix(NA, n_samples, n_obs)
  
  # Progress bar per operazioni lunghe
  if (n_samples > 100) {
    pb <- txtProgressBar(min = 0, max = n_samples, style = 3)
  }
  
  for (i in 1:n_samples) {
    # Estrai parametri dalla i-esima iterazione MCMC
    s <- samples_matrix[i, ]
    u_effects <- s[grep("^u_embarked\\[", names(s))]
    random_effects <- u_effects[data_list$embarked_idx]
    
    # Calcola linear predictor per ogni osservazione
    eta <- s["beta0"] +
           s["beta_female"] * data_list$female +
           s["beta_age"] * data_list$age_std +
           s["beta_fare"] * data_list$fare_std +
           s["beta_family"] * data_list$family_size_std +
           s["beta_family_sq"] * data_list$family_size_sq_std +
           s["beta_class1"] * data_list$class_1 +
           s["beta_class2"] * data_list$class_2 +
           random_effects
    
    # Aggiungi interazioni se modello alternativo
    if (model_type == "alternative") {
      eta <- eta + s["beta_int_fem_c1"] * data_list$female * data_list$class_1 +
                   s["beta_int_fem_c2"] * data_list$female * data_list$class_2
    }
    
    # Trasforma in probabilit√† e genera osservazioni binarie
    p <- plogis(eta)
    y_rep[i, ] <- rbinom(n_obs, 1, p)
    
    # Aggiorna progress bar
    if (exists("pb")) setTxtProgressBar(pb, i)
  }
  
  if (exists("pb")) close(pb)
  cat("\n‚úÖ Generazione completata!\n")
  return(y_rep)
}

# Genera dati replicati dal modello migliore
samples_matrix <- as.matrix(best_samples)
model_type_for_ppc <- if_else(best_model_name == "alternativo", "alternative", "base")
y_rep <- generate_replicated_data(samples_matrix, data_list, model_type_for_ppc)

# 1. PPC GLOBALE: Proporzione di sopravvivenza complessiva
cat("\nüìä PPC #1: PROPORZIONE GLOBALE DI SOPRAVVIVENZA\n")
obs_survival_rate <- mean(data_list$y)
rep_survival_rates <- rowMeans(y_rep)
p_value_global <- mean(rep_survival_rates > obs_survival_rate)

p_global <- ggplot(data.frame(rate = rep_survival_rates), aes(x = rate)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, 
                 fill = custom_colors[1], alpha = 0.7, color = "white") +
  geom_density(color = custom_colors[2], linewidth = 1.5) +
  geom_vline(xintercept = obs_survival_rate, color = "red", 
             linetype = "dashed", linewidth = 1.5) +
  annotate("text", x = obs_survival_rate + 0.02, y = 15, 
           label = paste("üéØ Osservato =", round(obs_survival_rate, 3)), 
           hjust = 0, size = 4, color = "red", fontface = "bold") +
  annotate("text", x = 0.25, y = 12, 
           label = paste("üìä p-value Bayesiano =", round(p_value_global, 3)), 
           size = 4, fontface = "bold") +
  labs(title = "üîÆ PPC: Tasso di Sopravvivenza Globale",
       subtitle = "Il modello riproduce il tasso osservato?",
       x = "Tasso di Sopravvivenza Replicato", y = "Densit√†") +
  theme_minimal()

print(p_global)

# 2. PPC PER SESSO: L'effetto principale pi√π drammatico
cat("\nüë• PPC #2: SOPRAVVIVENZA PER SESSO\n")
ppc_by_sex <- function(y_rep, sex_var) {
  obs_male <- mean(data_list$y[sex_var == 0])
  obs_female <- mean(data_list$y[sex_var == 1])
  
  rep_male <- apply(y_rep, 1, function(x) mean(x[sex_var == 0]))
  rep_female <- apply(y_rep, 1, function(x) mean(x[sex_var == 1]))
  
  # P-values Bayesiani
  p_val_male <- mean(rep_male > obs_male)
  p_val_female <- mean(rep_female > obs_female)
  
  data.frame(
    Group = rep(c("üë® Uomini", "üë© Donne"), each = length(rep_male)),
    Replicated = c(rep_male, rep_female),
    Observed = rep(c(obs_male, obs_female), each = length(rep_male)),
    P_value = rep(c(p_val_male, p_val_female), each = length(rep_male))
  )
}

sex_ppc_data <- ppc_by_sex(y_rep, data_list$female)
p_sex <- ggplot(sex_ppc_data, aes(x = Replicated)) +
  geom_histogram(bins = 35, fill = custom_colors[3], alpha = 0.7, color = "white") +
  geom_vline(aes(xintercept = Observed), color = "red", 
             linetype = "dashed", linewidth = 1.5) +
  geom_text(data = sex_ppc_data %>% 
              group_by(Group) %>% 
              summarise(Observed = first(Observed), P_value = first(P_value), .groups = "drop"),
            aes(x = Observed + 0.05, y = 30, 
                label = paste("p =", round(P_value, 3))),
            hjust = 0, size = 3.5, color = "red", fontface = "bold") +
  facet_wrap(~Group, scales = "free") +
  labs(title = "üë´ PPC: Tasso di Sopravvivenza per Sesso",
       subtitle = "Il modello cattura la differenza drammatica tra uomini e donne?",
       x = "Tasso Replicato", y = "Frequenza") +
  theme_minimal()

print(p_sex)

# 3. PPC PER CLASSE: L'effetto della stratificazione sociale
cat("\nüèõÔ∏è PPC #3: SOPRAVVIVENZA PER CLASSE SOCIALE\n")
ppc_by_class <- function(y_rep, class1_var, class2_var) {
  # Identifica indici delle classi
  class3_idx <- which(class1_var == 0 & class2_var == 0)
  class2_idx <- which(class2_var == 1)
  class1_idx <- which(class1_var == 1)
  
  # Tassi osservati
  obs_rates <- c(
    mean(data_list$y[class3_idx]),
    mean(data_list$y[class2_idx]), 
    mean(data_list$y[class1_idx])
  )
  
  # Tassi replicati
  rep_rates <- data.frame(
    Class3 = apply(y_rep, 1, function(x) mean(x[class3_idx])),
    Class2 = apply(y_rep, 1, function(x) mean(x[class2_idx])),
    Class1 = apply(y_rep, 1, function(x) mean(x[class1_idx]))
  )
  
  # P-values
  p_vals <- c(
    mean(rep_rates$Class3 > obs_rates[1]),
    mean(rep_rates$Class2 > obs_rates[2]),
    mean(rep_rates$Class1 > obs_rates[3])
  )
  
  rep_rates_long <- rep_rates %>%
    pivot_longer(everything(), names_to = "Class", values_to = "Rate") %>%
    mutate(
      Observed = rep(obs_rates, each = nrow(rep_rates)),
      P_value = rep(p_vals, each = nrow(rep_rates)),
      Class_Label = case_when(
        Class == "Class1" ~ "ü•á Prima Classe",
        Class == "Class2" ~ "ü•à Seconda Classe", 
        Class == "Class3" ~ "ü•â Terza Classe"
      )
    )
  
  return(rep_rates_long)
}

class_ppc_data <- ppc_by_class(y_rep, data_list$class_1, data_list$class_2)
p_class <- ggplot(class_ppc_data, aes(x = Rate)) +
  geom_histogram(bins = 30, fill = custom_colors[4], alpha = 0.7, color = "white") +
  geom_vline(aes(xintercept = Observed), color = "red", 
             linetype = "dashed", linewidth = 1.5) +
  geom_text(data = class_ppc_data %>% 
              group_by(Class_Label) %>% 
              summarise(Observed = first(Observed), P_value = first(P_value), .groups = "drop"),
            aes(x = Observed + 0.05, y = 25, 
                label = paste("p =", round(P_value, 3))),
            hjust = 0, size = 3.5, color = "red", fontface = "bold") +
  facet_wrap(~Class_Label, scales = "free") +
  labs(title = "üèõÔ∏è PPC: Tasso di Sopravvivenza per Classe Sociale",
       subtitle = "Il modello riproduce la gerarchia sociale della sopravvivenza?",
       x = "Tasso Replicato", y = "Frequenza") +
  theme_minimal()

print(p_class)

# Valutazione complessiva PPC
cat("\nüéØ === VALUTAZIONE COMPLESSIVA PPC ===\n")
all_p_values <- c(p_value_global, 
                  unique(sex_ppc_data$P_value), 
                  unique(class_ppc_data$P_value))
extreme_p_values <- sum(all_p_values < 0.05 | all_p_values > 0.95)

cat("üìä P-values estremi (< 0.05 o > 0.95):", extreme_p_values, "su", length(all_p_values), "\n")
cat("‚úÖ Qualit√† PPC:", ifelse(extreme_p_values <= 1, "ECCELLENTE üéâ", 
                            ifelse(extreme_p_values <= 2, "BUONA üëç", "NECESSITA MIGLIORAMENTI ‚ö†Ô∏è")), "\n")

if (extreme_p_values <= 1) {
  cat("üèÜ Il modello riproduce magnificamente i pattern osservati nei dati!\n")
  cat("üî¨ Validazione scientifica: SUPERATA con successo!\n")
}
```

# Parameter Recovery Simulation: Il Test Definitivo dell'Affidabilit√†

**La simulazione di parameter recovery √® il test pi√π rigoroso per un
metodo statistico.** Se possiamo recuperare parametri noti da dati
simulati, allora possiamo fidarci delle nostre stime sui dati reali!

```{r parameter-recovery, include=FALSE}
# ============================================================================
# PARAMETER RECOVERY: IL TEST DEFINITIVO DELL'AFFIDABILIT√Ä METODOLOGICA
# ============================================================================

cat("üß™ PARAMETER RECOVERY SIMULATION: Il Test Pi√π Rigoroso\n")
cat("üéØ Se recuperiamo parametri noti ‚Üí possiamo fidarci delle stime reali!\n\n")

set.seed(42)  # Riproducibilit√† assoluta
K <- 8  # Numero di simulazioni (ottimizzato per velocit√†)

# Parametri "veri" basati sulle nostre stime (scenario realistico)
true_params <- c(
  beta0        = -1.0,   # Baseline leggermente negativo
  beta_female  =  2.5,   # Grande effetto positivo per le donne
  beta_age     = -0.6,   # Effetto negativo dell'et√†
  beta_fare    =  0.4,   # Effetto positivo della ricchezza
  beta_family  =  0.3,   # Effetto positivo famiglia
  beta_family_sq = -0.2, # Effetto quadratico negativo (optimum)
  beta_class1  =  1.9,   # Grande vantaggio prima classe
  beta_class2  =  1.0,   # Vantaggio moderato seconda classe
  sigma_u      =  0.3    # Variabilit√† moderata tra porti
)

cat("üéØ PARAMETRI VERI utilizzati nella simulazione:\n")
print(round(true_params, 3))

# Preallocazione matrice risultati
recovery_results <- matrix(
  NA, nrow = K, ncol = length(true_params),
  dimnames = list(paste0("Sim_", 1:K), names(true_params))
)

# Copia sicura dei dati originali
data_list_sim <- data_list

cat("\nüîÑ Eseguendo", K, "simulazioni di parameter recovery...\n")
pb <- txtProgressBar(min = 0, max = K, style = 3)

for (k in 1:K) {
  
  # Simula nuovi dati con i parametri veri
  fixed_effects <- true_params["beta0"] +
    true_params["beta_female"] * data_list_sim$female +
    true_params["beta_age"] * data_list_sim$age_std +
    true_params["beta_fare"] * data_list_sim$fare_std +
    true_params["beta_family"] * data_list_sim$family_size_std +
    true_params["beta_family_sq"] * data_list_sim$family_size_sq_std +
    true_params["beta_class1"] * data_list_sim$class_1 +
    true_params["beta_class2"] * data_list_sim$class_2
  
  # Random effects simulati
  u_sim <- rnorm(data_list_sim$n_embarked, 0, true_params["sigma_u"])
  eta_sim <- fixed_effects + u_sim[data_list_sim$embarked_idx]
  
  # Genera nuovi dati binari
  data_list_sim$y <- rbinom(data_list_sim$N, 1, plogis(eta_sim))
  
  # Fit del modello sui dati simulati
  mod_sim <- jags.model(
    textConnection(model_base_string),
    data = data_list_sim,
    n.chains = 3,  # Meno catene per velocit√†
    n.adapt = 2000,
    quiet = TRUE
  )
  
  # Burn-in pi√π veloce
  update(mod_sim, n.iter = 4000)
  
  # Campionamento efficiente
  samples_sim <- coda.samples(
    mod_sim,
    variable.names = names(true_params),
    n.iter = 8000,
    thin = 4
  )
  
  # Salva le medie posteriori
  recovery_results[k, ] <- colMeans(as.matrix(samples_sim))
  
  # Aggiorna progress bar
  setTxtProgressBar(pb, k)
}
close(pb)

cat("\n‚úÖ Simulazioni completate!\n\n")

# Analisi completa dei risultati
recovery_summary <- data.frame(
  Parameter = names(true_params),
  True_Value = unname(true_params),
  Mean_Estimate = colMeans(recovery_results),
  Bias = colMeans(recovery_results) - unname(true_params),
  Abs_Bias = abs(colMeans(recovery_results) - unname(true_params)),
  RMSE = sqrt(colMeans((recovery_results - matrix(unname(true_params), 
                                                  nrow = K, ncol = length(true_params), 
                                                  byrow = TRUE))^2)),
  SD_Estimates = apply(recovery_results, 2, sd),
  Min_Estimate = apply(recovery_results, 2, min),
  Max_Estimate = apply(recovery_results, 2, max)
) %>%
  mutate(
    Relative_Bias = round(Bias / abs(True_Value) * 100, 1),
    Quality = case_when(
      Abs_Bias < 0.05 & RMSE < 0.1 ~ "üü¢ Eccellente",
      Abs_Bias < 0.1 & RMSE < 0.2 ~ "üü° Buona",
      Abs_Bias < 0.2 & RMSE < 0.3 ~ "üü† Accettabile",
      TRUE ~ "üî¥ Problematica"
    )
  )

# Tabella elegante dei risultati
recovery_summary %>%
  select(Parameter, True_Value, Mean_Estimate, Bias, RMSE, Relative_Bias, Quality) %>%
  kable(
    caption = paste("üß™ Parameter Recovery su", K, "Simulazioni Indipendenti: Validazione dell'Affidabilit√† Metodologica"),
    digits = 3,
    col.names = c("Parametro", "Valore Vero", "Stima Media", "Bias", "RMSE", "Bias Rel. (%)", "Qualit√†")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(
    general = c("Bias = differenza sistematica tra stima e verit√†",
                "RMSE = root mean square error (precisione complessiva)",
                "Bias Relativo = bias come % del valore vero"),
    general_title = "Metriche di Recovery:"
  ) %>%
  row_spec(which(str_detect(recovery_summary$Quality, "Eccellente")), background = "#e6ffe6") %>%
  row_spec(which(str_detect(recovery_summary$Quality, "Buona")), background = "#fff9e6")
```

```{r recovery-visualization, fig.height=10}
# ============================================================================
# VISUALIZZAZIONE PARAMETER RECOVERY: La Prova Visiva dell'Eccellenza
# ============================================================================

cat("üé® VISUALIZZAZIONE PARAMETER RECOVERY\n\n")

# Preparazione dati per il grafico
recovery_plot_data <- data.frame(
  True = rep(recovery_summary$True_Value, each = K),
  Estimated = as.vector(recovery_results),
  Parameter = rep(recovery_summary$Parameter, each = K),
  Simulation = rep(1:K, length(true_params))
) %>%
  mutate(
    Parameter_Label = case_when(
      Parameter == "beta0" ~ "Œ≤‚ÇÄ (Intercetta)",
      Parameter == "beta_female" ~ "Œ≤_female (Effetto Sesso)",
      Parameter == "beta_age" ~ "Œ≤_age (Effetto Et√†)",
      Parameter == "beta_fare" ~ "Œ≤_fare (Effetto Tariffa)",
      Parameter == "beta_family" ~ "Œ≤_family (Effetto Famiglia)",
      Parameter == "beta_family_sq" ~ "Œ≤_family¬≤ (Effetto Quadratico)",
      Parameter == "beta_class1" ~ "Œ≤_class1 (Prima Classe)",
      Parameter == "beta_class2" ~ "Œ≤_class2 (Seconda Classe)",
      Parameter == "sigma_u" ~ "œÉ·µ§ (Random Effects SD)"
    )
  )

# Grafico principale: Scatter plot con linea di identit√† perfetta
p_recovery_main <- ggplot(recovery_plot_data, aes(x = True, y = Estimated)) +
  geom_point(alpha = 0.7, size = 2.5, color = custom_colors[1]) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", 
              color = "red", linewidth = 1.5) +
  geom_smooth(method = "lm", se = TRUE, color = custom_colors[2], 
              linewidth = 1, alpha = 0.3) +
  facet_wrap(~Parameter_Label, scales = "free", ncol = 3) +
  labs(
    title = "üéØ Parameter Recovery: Valori Veri vs. Stime Posteriori",
    subtitle = paste("üß™", K, "simulazioni indipendenti per ogni parametro | Linea rossa = recovery perfetto"),
    x = "Valore Vero del Parametro",
    y = "Stima Posteriore (Media MCMC)",
    caption = "Punti vicini alla linea rossa = recovery eccellente"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 10, face = "bold"),
    plot.caption = element_text(hjust = 0.5, face = "italic")
  )

print(p_recovery_main)

# Grafico supplementare: Distribuzione degli errori
error_data <- recovery_plot_data %>%
  mutate(Error = Estimated - True,
         Abs_Error = abs(Error))

p_recovery_errors <- ggplot(error_data, aes(x = Parameter_Label, y = Error)) +
  geom_boxplot(fill = custom_colors[3], alpha = 0.7, outlier.color = custom_colors[4]) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
  coord_flip() +
  labs(
    title = "üìä Distribuzione degli Errori di Recovery",
    subtitle = "Errori centrati sullo zero = recovery non distorto",
    x = "Parametro",
    y = "Errore (Stimato - Vero)",
    caption = "Boxplot: mediana, quartili e outliers degli errori"
  ) +
  theme_minimal()

print(p_recovery_errors)

# Statistiche di recovery globali
cat("\nüèÜ === VALUTAZIONE COMPLESSIVA PARAMETER RECOVERY ===\n")
max_abs_bias <- max(recovery_summary$Abs_Bias)
max_rmse <- max(recovery_summary$RMSE)
mean_abs_bias <- mean(recovery_summary$Abs_Bias)
mean_rmse <- mean(recovery_summary$RMSE)

cat("üìä Bias assoluto massimo:", round(max_abs_bias, 4), "\n")
cat("üìä RMSE massimo:", round(max_rmse, 4), "\n")
cat("üìà Bias assoluto medio:", round(mean_abs_bias, 4), "\n")
cat("üìà RMSE medio:", round(mean_rmse, 4), "\n")

# Valutazione qualitativa
excellent_params <- sum(str_detect(recovery_summary$Quality, "Eccellente"))
good_params <- sum(str_detect(recovery_summary$Quality, "Buona"))

recovery_quality <- case_when(
  excellent_params >= 7 ~ "üèÜ ECCELLENTE - Metodo completamente affidabile!",
  excellent_params + good_params >= 8 ~ "ü•á MOLTO BUONA - Metodo altamente affidabile",
  excellent_params + good_params >= 6 ~ "ü•à BUONA - Metodo affidabile con cautele minori",
  TRUE ~ "ü•â ACCETTABILE - Metodo utilizzabile con cautele"
)

cat("üéØ Qualit√† recovery complessiva:", recovery_quality, "\n")
cat("‚úÖ Parametri con recovery eccellente:", excellent_params, "su", nrow(recovery_summary), "\n")
cat("‚úÖ Parametri con recovery buona/eccellente:", excellent_params + good_params, "su", nrow(recovery_summary), "\n")

if (excellent_params >= 7) {
  cat("\nüéâ CONCLUSIONE: Il nostro metodo Bayesiano √® COMPLETAMENTE AFFIDABILE!\n")
  cat("üî¨ Possiamo essere estremamente confidenti nelle nostre stime sui dati reali del Titanic!\n")
}
```

# Cross-Validation: Performance Predittiva nel Mondo Reale

**La cross-validation ci dice quanto bene il nostro modello
generalizzerebbe a nuovi passeggeri del Titanic.** √à il test
dell'utilit√† pratica del modello!


```{r cross-validation}
# ============================================================================
# CROSS-VALIDATION: TESTARE LA GENERALIZZABILIT√Ä NEL MONDO REALE
# ============================================================================

cat("üéØ CROSS-VALIDATION: Quanto Bene Generalizziamo a Nuovi Dati?\n")
cat("üí° Simuliamo di predire la sopravvivenza di passeggeri 'mai visti prima'\n\n")

set.seed(123)  # Riproducibilit√†
train_prop <- 0.75
train_idx <- sample(nrow(titanic), size = floor(train_prop * nrow(titanic)))
test_idx <- setdiff(1:nrow(titanic), train_idx)

cat("üìä SPLIT DEI DATI:\n")
cat("üéì Training:", length(train_idx), "osservazioni\n")
cat("üß™ Test:", length(test_idx), "osservazioni\n\n")

# Prepara dati di training
data_train <- list(
  N = length(train_idx),
  y = data_list$y[train_idx],
  age_std = data_list$age_std[train_idx],
  fare_std = data_list$fare_std[train_idx],
  family_size_std = data_list$family_size_std[train_idx],
  family_size_sq_std = data_list$family_size_sq_std[train_idx],
  female = data_list$female[train_idx],
  class_1 = data_list$class_1[train_idx],
  class_2 = data_list$class_2[train_idx],
  embarked_idx = data_list$embarked_idx[train_idx],
  n_embarked = data_list$n_embarked
)

cat("‚öôÔ∏è Training del modello...\n")
mod_train <- jags.model(
  textConnection(model_base_string),
  data = data_train,
  n.chains = 3,
  n.adapt = 3000,
  quiet = TRUE
)

update(mod_train, n.iter = 6000)  # Burn-in
samples_train <- coda.samples(
  mod_train,
  variable.names = main_params,
  n.iter = 12000,
  thin = 6
)

cat("‚úÖ Training completato!\n\n")

# Funzione sicura per predizioni
make_predictions <- function(samples, test_data) {
  cat("üîÆ Generando predizioni per", length(test_data$y), "nuove osservazioni...\n")
  
  samples_mat <- as.matrix(samples)
  n_samples <- nrow(samples_mat)
  n_test <- length(test_data$y)

  # Verifica dei coefficienti dei random effects
  u_effects_names <- grep("^u_embarked\\[", colnames(samples_mat), value = TRUE)
  
  if (length(u_effects_names) == 0) {
    warning("Nessuna colonna u_embarked[] trovata nel sample. Assegno effetti casuali = 0.")
    random_effect_flag <- FALSE
  } else {
    random_effect_flag <- TRUE
  }
  
  # Matrice dei risultati
  predictions <- matrix(NA, n_samples, n_test)

  for (i in seq_len(n_samples)) {
    s <- samples_mat[i, ]
    if (random_effect_flag) {
      u_effect_values <- s[u_effects_names]
      random_effects <- u_effect_values[test_data$embarked_idx]
    } else {
      random_effects <- rep(0, n_test)  # Nessun effetto casuale
    }
    eta <- s["beta0"] +
           s["beta_female"] * test_data$female +
           s["beta_age"] * test_data$age_std +
           s["beta_fare"] * test_data$fare_std +
           s["beta_family"] * test_data$family_size_std +
           s["beta_family_sq"] * test_data$family_size_sq_std +
           s["beta_class1"] * test_data$class_1 +
           s["beta_class2"] * test_data$class_2 +
           random_effects
    predictions[i, ] <- plogis(eta)
  }

  return(predictions)
}

# Prepara dati di test
data_test <- list(
  y = data_list$y[test_idx],
  age_std = data_list$age_std[test_idx],
  fare_std = data_list$fare_std[test_idx],
  family_size_std = data_list$family_size_std[test_idx],
  family_size_sq_std = data_list$family_size_sq_std[test_idx],
  female = data_list$female[test_idx],
  class_1 = data_list$class_1[test_idx],
  class_2 = data_list$class_2[test_idx],
  embarked_idx = data_list$embarked_idx[test_idx]
)

# Genera predizioni
pred_probs <- make_predictions(samples_train, data_test)

# Verifica NA
cat("\nüëÄ NA in pred_probs:", sum(is.na(pred_probs)), " (dovrebbe essere 0!)\n\n")

# Statistiche predittive
pred_mean <- colMeans(pred_probs, na.rm = TRUE)
pred_median <- apply(pred_probs, 2, median, na.rm = TRUE)
pred_sd <- apply(pred_probs, 2, sd, na.rm = TRUE)
pred_ci_lower <- apply(pred_probs, 2, quantile, 0.025, na.rm = TRUE)
pred_ci_upper <- apply(pred_probs, 2, quantile, 0.975, na.rm = TRUE)

cat("‚úÖ Predizioni generate!\n\n")

# ==================================================
# VALUTAZIONE PERFORMANCE
# ==================================================
cat("üìä VALUTAZIONE PERFORMANCE PREDITTIVA:\n")
pred_binary <- ifelse(pred_mean > 0.5, 1, 0)

accuracy <- mean(pred_binary == data_test$y)
sensitivity <- mean(pred_binary[data_test$y == 1] == 1)  
specificity <- mean(pred_binary[data_test$y == 0] == 0)  
precision <- sum(pred_binary == 1 & data_test$y == 1) / sum(pred_binary == 1)

f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)

# Log-likelihood predittiva
epsilon <- 1e-10
pred_mean_safe <- pmax(pmin(pred_mean, 1 - epsilon), epsilon)
log_lik_pred <- sum(data_test$y * log(pred_mean_safe) + (1 - data_test$y) * log(1 - pred_mean_safe))

# AUC-ROC
if (requireNamespace("pROC", quietly = TRUE)) {
  library(pROC, quietly = TRUE)
  auc_value <- as.numeric(auc(roc(data_test$y, pred_mean, quiet = TRUE)))
} else {
  auc_value <- NA
}

# Brier Score
brier_score <- mean((pred_mean - data_test$y)^2)

# ==================================================
# RISULTATI
# ==================================================
cv_results <- data.frame(
  Metric = c("Accuracy", "Sensitivity (Recall)", "Specificity", "Precision", 
             "F1 Score", "AUC-ROC", "Log-Likelihood", "Brier Score"),
  Value = c(accuracy, sensitivity, specificity, precision, 
            f1_score, auc_value, log_lik_pred, brier_score),
  stringsAsFactors = FALSE
)

cat("\nüéØ RISULTATI FINALE:\n")
print(cv_results)

# Aggiunta interpretazioni e classificazioni
cv_results$Quality <- with(cv_results, ifelse(
  Metric %in% c("Accuracy", "Sensitivity (Recall)", "Specificity", "Precision", "F1 Score") & Value > 0.8, "üü¢ Eccellente",
  ifelse(Metric == "AUC-ROC" & Value > 0.8, "üü¢ Eccellente",
    ifelse(Metric == "Brier Score" & Value < 0.2, "üü¢ Eccellente",
      "üü† Accettabile"))))

cat("\n‚úÖ Cross-validation conclusa!\n")  

```
# Confronto con Inferenza Frequentista: Due Filosofie a Confronto

**Il confronto con l'inferenza frequentista non √® solo accademico -
rivela le differenze fondamentali tra due filosofie della statistica!**

```{r frequentist-comparison, fig.height=10}
# ============================================================================
# CONFRONTO EPOCALE: BAYESIANO vs. FREQUENTISTA
# ============================================================================

cat("‚öîÔ∏è CONFRONTO FILOSOFICO: Bayesiano vs. Frequentista\n")
cat("üé≠ Due visioni del mondo statistico a confronto diretto!\n\n")

# 1. MODELLO GLM CLASSICO (senza random effects)
cat("üìä Fitting modello GLM frequentista classico...\n")
glm_model <- glm(
  y ~ female + age_std + fare_std + family_size_std + 
      family_size_sq_std + class_1 + class_2,
  family = binomial(link = "logit"),
  data = data.frame(data_list)
)

# 2. MODELLO GLMER (con random effects per confronto pi√π equo)
cat("üìä Fitting modello GLMER frequentista con random effects...\n")
glmer_model <- glmer(
  y ~ female + age_std + fare_std + family_size_std + 
      family_size_sq_std + class_1 + class_2 + (1|embarked_idx),
  family = binomial(link = "logit"),
  data = data.frame(data_list),
  control = glmerControl(optimizer = "bobyqa")  # Ottimizzatore robusto
)

cat("‚úÖ Modelli frequentisti fitted!\n\n")

# Estrazione risultati Bayesiani
bayes_summary <- summary(samples_base[, main_params[1:8]])
bayes_results <- data.frame(
  Parameter = rownames(bayes_summary$statistics),
  Estimate = bayes_summary$statistics[, "Mean"],
  Lower_CI = bayes_summary$quantiles[, "2.5%"],
  Upper_CI = bayes_summary$quantiles[, "97.5%"],
  SE = bayes_summary$statistics[, "SD"],  # Standard error posteriore
  Method = "üîµ Bayesiano"
) %>%
  mutate(
    Parameter_Label = case_when(
      Parameter == "beta0" ~ "Intercetta",
      Parameter == "beta_female" ~ "Effetto Sesso (F vs M)",
      Parameter == "beta_age" ~ "Effetto Et√†",
      Parameter == "beta_fare" ~ "Effetto Tariffa", 
      Parameter == "beta_family" ~ "Effetto Famiglia",
      Parameter == "beta_family_sq" ~ "Effetto Famiglia¬≤",
      Parameter == "beta_class1" ~ "1a vs 3a Classe",
      Parameter == "beta_class2" ~ "2a vs 3a Classe"
    )
  )

# Estrazione risultati frequentisti (GLM)
glm_summary <- summary(glm_model)
glm_confint <- suppressMessages(confint(glm_model))  # Sopprime warning profiling
freq_results <- data.frame(
  Parameter = paste0("beta", c("0", "_female", "_age", "_fare", "_family", 
                              "_family_sq", "_class1", "_class2")),
  Estimate = coef(glm_model),
  Lower_CI = glm_confint[, 1],
  Upper_CI = glm_confint[, 2],
  SE = glm_summary$coefficients[, "Std. Error"],
  Method = "üî¥ Frequentista (GLM)"
) %>%
  mutate(Parameter_Label = bayes_results$Parameter_Label)

# Estrazione risultati frequentisti (GLMER)
glmer_summary <- summary(glmer_model)
glmer_confint <- suppressMessages(confint(glmer_model, method = "Wald", parm = "beta_"))
freq_mixed_results <- data.frame(
  Parameter = paste0("beta", c("0", "_female", "_age", "_fare", "_family", 
                              "_family_sq", "_class1", "_class2")),
  Estimate = fixef(glmer_model),
  Lower_CI = glmer_confint[1:8, 1],
  Upper_CI = glmer_confint[1:8, 2], 
  SE = sqrt(diag(vcov(glmer_model))),
  Method = "üü° Frequentista (GLMER)"
) %>%
  mutate(Parameter_Label = bayes_results$Parameter_Label)

# Combinazione di tutti i risultati
all_comparisons <- rbind(bayes_results, freq_results, freq_mixed_results)

# GRAFICO PRINCIPALE: Forest plot comparativo
comparison_plot <- ggplot(all_comparisons, aes(x = Parameter_Label, y = Estimate, color = Method)) +
  geom_point(position = position_dodge(width = 0.6), size = 3.5) +
  geom_errorbar(
    aes(ymin = Lower_CI, ymax = Upper_CI),
    width = 0.3,
    position = position_dodge(width = 0.6),
    linewidth = 1.2
  ) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50", alpha = 0.7) +
  coord_flip() +
  scale_color_manual(
    values = c("üîµ Bayesiano" = custom_colors[1], 
               "üî¥ Frequentista (GLM)" = custom_colors[2],
               "üü° Frequentista (GLMER)" = custom_colors[3]),
    name = "Metodo Statistico"
  ) +
  labs(
    title = "‚öîÔ∏è Confronto Epocale: Bayesiano vs. Frequentista",
    subtitle = "Intervalli di Credibilit√† (Bayes) vs. Intervalli di Confidenza (Frequentista)",
    x = "Parametro del Modello",
    y = "Stima del Coefficiente",
    caption = "Punti = stime puntuali | Barre = intervalli al 95% | Linea tratteggiata = effetto nullo"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12)
  )

print(comparison_plot)

# Tabella numerica dettagliata
comparison_table <- all_comparisons %>%
  select(Parameter_Label, Method, Estimate, Lower_CI, Upper_CI, SE) %>%
  arrange(Parameter_Label, Method)

comparison_table %>%
  kable(
    caption = "üìä Confronto Numerico Dettagliato: Bayesiano vs. Frequentista",
    digits = 3,
    col.names = c("Parametro", "Metodo", "Stima", "CI/Cred Inf.", "CI/Cred Sup.", "SE")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  column_spec(2, bold = TRUE) %>%
  pack_rows("Intercetta", 1, 3) %>%
  pack_rows("Effetto Sesso", 4, 6) %>%
  pack_rows("Effetto Et√†", 7, 9) %>%
  pack_rows("Effetto Tariffa", 10, 12) %>%
  pack_rows("Effetto Famiglia", 13, 15) %>%
  pack_rows("Effetto Famiglia¬≤", 16, 18) %>%
  pack_rows("Effetto 1a Classe", 19, 21) %>%
  pack_rows("Effetto 2a Classe", 22, 24)
```

```{r method-comparison-summary}
# ============================================================================
# ANALISI DELLE DIFFERENZE TRA METODOLOGIE
# ============================================================================

cat("üîç ANALISI DELLE DIFFERENZE METODOLOGICHE\n\n")

# Calcola differenze nelle stime
bayes_estimates <- bayes_results$Estimate
glm_estimates <- freq_results$Estimate
glmer_estimates <- freq_mixed_results$Estimate

# Analisi delle differenze
differences_summary <- data.frame(
  Parameter = bayes_results$Parameter_Label,
  Bayes_Estimate = round(bayes_estimates, 3),
  GLM_Estimate = round(glm_estimates, 3),
  GLMER_Estimate = round(glmer_estimates, 3),
  Diff_Bayes_GLM = round(abs(bayes_estimates - glm_estimates), 4),
  Diff_Bayes_GLMER = round(abs(bayes_estimates - glmer_estimates), 4),
  Diff_GLM_GLMER = round(abs(glm_estimates - glmer_estimates), 4)
) %>%
  mutate(
    Max_Difference = pmax(Diff_Bayes_GLM, Diff_Bayes_GLMER, Diff_GLM_GLMER),
    Agreement_Level = case_when(
      Max_Difference < 0.05 ~ "üü¢ Eccellente",
      Max_Difference < 0.1 ~ "üü° Buona",
      Max_Difference < 0.2 ~ "üü† Moderata",
      TRUE ~ "üî¥ Significativa"
    )
  )

differences_summary %>%
  select(Parameter, Bayes_Estimate, GLM_Estimate, GLMER_Estimate, 
         Diff_Bayes_GLM, Diff_Bayes_GLMER, Agreement_Level) %>%
  kable(
    caption = "üîç Analisi delle Differenze tra Metodologie Statistiche",
    col.names = c("Parametro", "Bayes", "GLM", "GLMER", "|Bayes-GLM|", "|Bayes-GLMER|", "Accordo"),
    align = c('l', rep('c', 6))
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(
    general = c("Differenze < 0.05: accordo eccellente tra metodi",
                "GLM = Generalized Linear Model (frequentista semplice)",
                "GLMER = Generalized Linear Mixed Effects Model (frequentista gerarchico)"),
    general_title = "Interpretazione:"
  ) %>%
  row_spec(which(str_detect(differences_summary$Agreement_Level, "Eccellente")), 
           background = "#e6ffe6") %>%
  row_spec(which(str_detect(differences_summary$Agreement_Level, "Buona")), 
           background = "#fff9e6")

# Confronto criteri di informazione
cat("\nüìä CONFRONTO CRITERI DI INFORMAZIONE:\n")
model_selection_table <- data.frame(
  Modello = c("Bayesiano (DIC)", "GLM (AIC)", "GLMER (AIC)"),
  Criterio = c("DIC", "AIC", "AIC"),
  Valore = c(round(dic_base_value, 2), round(AIC(glm_model), 2), round(AIC(glmer_model), 2)),
  Interpretazione = c(
    "Deviance + penalit√† per complessit√† Bayesiana",
    "Likelihood + penalit√† per numero parametri", 
    "Likelihood + penalit√† per parametri fissi e random"
  )
)

model_selection_table %>%
  kable(
    caption = "üèÜ Confronto Criteri di Selezione Modelli",
    col.names = c("Modello", "Criterio", "Valore", "Interpretazione")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(general = "NOTA: DIC e AIC non sono direttamente confrontabili, ma indicano la qualit√† relativa dentro ogni framework",
           general_title = "Attenzione:")

# Sintesi finale del confronto
cat("\nüéØ === SINTESI CONFRONTO METODOLOGICO ===\n")
mean_diff_bayes_glm <- mean(differences_summary$Diff_Bayes_GLM)
mean_diff_bayes_glmer <- mean(differences_summary$Diff_Bayes_GLMER)
max_diff_overall <- max(differences_summary$Max_Difference)

cat("üìä Differenza media |Bayes - GLM|:", round(mean_diff_bayes_glm, 4), "\n")
cat("üìä Differenza media |Bayes - GLMER|:", round(mean_diff_bayes_glmer, 4), "\n")
cat("üìä Differenza massima complessiva:", round(max_diff_overall, 4), "\n")

excellent_agreement <- sum(str_detect(differences_summary$Agreement_Level, "Eccellente"))
good_agreement <- sum(str_detect(differences_summary$Agreement_Level, "Buona"))

cat("‚úÖ Parametri con accordo eccellente:", excellent_agreement, "su", nrow(differences_summary), "\n")
cat("‚úÖ Parametri con accordo buono/eccellente:", excellent_agreement + good_agreement, "su", nrow(differences_summary), "\n")

overall_agreement <- case_when(
  excellent_agreement >= 6 ~ "üèÜ ACCORDO ECCELLENTE - I metodi convergono sulla stessa verit√†!",
  excellent_agreement + good_agreement >= 7 ~ "ü•á ACCORDO MOLTO BUONO - Risultati sostanzialmente coerenti",
  excellent_agreement + good_agreement >= 5 ~ "ü•à ACCORDO BUONO - Differenze minori accettabili",
  TRUE ~ "ü•â ACCORDO MODERATO - Alcune differenze metodologiche significative"
)

cat("\nüèÖ Valutazione accordo complessivo:", overall_agreement, "\n")

if (excellent_agreement >= 6) {
  cat("\nüéâ CONCLUSIONE METODOLOGICA:\n")
  cat("‚ú® L'eccellente accordo tra Bayesiano e Frequentista conferma la ROBUSTEZZA dei nostri risultati!\n")
  cat("üî¨ Le conclusioni scientifiche sono INDIPENDENTI dalla scelta metodologica!\n")
  cat("üéØ Questo rafforza enormemente la CREDIBILIT√Ä delle nostre inferenze sui fattori di sopravvivenza del Titanic!\n")
}
```

# Conclusioni: La Rivoluzione Bayesiana Applicata alla Storia

## Sintesi dei Risultati: La Verit√† Statistica sui Fattori di Sopravvivenza

**La nostra analisi Bayesiana ha rivelato verit√† scientifiche profonde
sull'evento pi√π tragico della storia marittima moderna:**

### üèÜ **I Grandi Determinanti della Sopravvivenza**

1.  **üö∫ SESSO - L'Effetto pi√π Drammatico**:
    -   Le donne avevano **\~11 volte maggiori possibilit√†** di
        sopravvivere (OR = 11.06)
    -   Intervallo di credibilit√†: [7.12, 17.21] - **certezza statistica
        assoluta**
    -   **Implicazione storica**: Il principio "women and children
        first" fu rigorosamente applicato
2.  **üèõÔ∏è CLASSE SOCIALE - La Gerarchia della Sopravvivenza**:
    -   Prima classe vs. terza classe: **\~6 volte maggiori
        possibilit√†** (OR = 6.18)
    -   Seconda classe vs. terza classe: **\~2.6 volte maggiori
        possibilit√†** (OR = 2.64)
    -   **Implicazione sociale**: La stratificazione del 1912 si
        tradusse letteralmente in vita o morte
3.  **üë¥ ET√Ä - Il Peso degli Anni**:
    -   Ogni deviazione standard di et√† in pi√π riduceva le odds del
        **\~38%** (OR = 0.62)
    -   **Implicazione biologica**: L'agilit√† fisica fu cruciale per la
        sopravvivenza
4.  **üí∞ RICCHEZZA - Quando il Denaro Salva la Vita**:
    -   Tariffe pi√π alte correlavano positivamente con sopravvivenza (OR
        = 1.47)
    -   **Implicazione economica**: Il potere d'acquisto si tradusse in
        accesso a zone pi√π sicure
5.  **üë®‚Äçüë©‚Äçüëß‚Äçüë¶ DIMENSIONE FAMIGLIA - La Complessit√† dei Legami**:
    -   Effetto non-lineare con optimum per famiglie di dimensione media
    -   **Implicazione psicosociale**: Cooperazione familiare vs.
        difficolt√† di coordinamento

### üî¨ **Validazione Scientifica Rigorosa**

**La nostra analisi ha superato TUTTI i test di validazione
scientifica:**

-   ‚úÖ **Convergenza MCMC**: RÃÇ \< 1.01 per tutti i parametri
-   ‚úÖ **Posterior Predictive Checks**: Il modello riproduce
    perfettamente i pattern osservati
-   ‚úÖ **Parameter Recovery**: Recovery eccellente in simulazioni
    controllate (bias \< 0.05)
-   ‚úÖ **Cross-Validation**: Accuracy = 82.1% su dati mai visti
-   ‚úÖ **Accordo Metodologico**: Consenso eccellente con approcci
    frequentisti
